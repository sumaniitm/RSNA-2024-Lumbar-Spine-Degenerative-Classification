{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install polars --no-index --find-links=file:///kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-28T06:14:44.649064Z","iopub.execute_input":"2024-09-28T06:14:44.649520Z","iopub.status.idle":"2024-09-28T06:14:50.138399Z","shell.execute_reply.started":"2024-09-28T06:14:44.649480Z","shell.execute_reply":"2024-09-28T06:14:50.137408Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in links: file:///kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\nProcessing /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg/polars-0.20.16-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nInstalling collected packages: polars\nSuccessfully installed polars-0.20.16\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport polars as pl\n#import duckdb as dd\n#from tqdm import tqdm\nimport matplotlib.pyplot as plt\n#import cv2\n#from pydicom import dcmread\nimport warnings\n#from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nimport pickle\n#import gc\nimport ctypes\nimport tensorflow as tf\nimport tensorflow_io as tfio\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2024-09-28T06:14:52.545370Z","iopub.execute_input":"2024-09-28T06:14:52.545729Z","iopub.status.idle":"2024-09-28T06:15:09.717221Z","shell.execute_reply.started":"2024-09-28T06:14:52.545695Z","shell.execute_reply":"2024-09-28T06:15:09.716373Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1727504102.192805      13 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD0928 06:15:02.201438501      13 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD0928 06:15:02.201453182      13 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD0928 06:15:02.201456497      13 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD0928 06:15:02.201458931      13 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD0928 06:15:02.201461303      13 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD0928 06:15:02.201463650      13 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD0928 06:15:02.201465946      13 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD0928 06:15:02.201468168      13 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD0928 06:15:02.201470404      13 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD0928 06:15:02.201472613      13 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD0928 06:15:02.201474932      13 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD0928 06:15:02.201477206      13 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD0928 06:15:02.201479433      13 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD0928 06:15:02.201481641      13 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD0928 06:15:02.201483871      13 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD0928 06:15:02.201486125      13 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD0928 06:15:02.201488520      13 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD0928 06:15:02.201490772      13 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD0928 06:15:02.201493007      13 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD0928 06:15:02.201495291      13 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD0928 06:15:02.201497499      13 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD0928 06:15:02.201499741      13 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD0928 06:15:02.201502085      13 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD0928 06:15:02.201504379      13 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD0928 06:15:02.201506534      13 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD0928 06:15:02.201508720      13 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD0928 06:15:02.201511031      13 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD0928 06:15:02.201513323      13 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD0928 06:15:02.201515663      13 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD0928 06:15:02.201518951      13 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD0928 06:15:02.201521293      13 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD0928 06:15:02.201523680      13 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD0928 06:15:02.201526087      13 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD0928 06:15:02.201528284      13 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD0928 06:15:02.201530497      13 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD0928 06:15:02.201532743      13 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD0928 06:15:02.201534942      13 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD0928 06:15:02.201537146      13 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD0928 06:15:02.201539540      13 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD0928 06:15:02.201541777      13 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD0928 06:15:02.201543937      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD0928 06:15:02.201546124      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD0928 06:15:02.201548379      13 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD0928 06:15:02.201550681      13 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD0928 06:15:02.201552952      13 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI0928 06:15:02.201738317      13 ev_epoll1_linux.cc:123]               grpc epoll fd: 60\nD0928 06:15:02.201750792      13 ev_posix.cc:113]                      Using polling engine: epoll1\nD0928 06:15:02.212361710      13 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0928 06:15:02.212373277      13 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0928 06:15:02.212381311      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0928 06:15:02.212384358      13 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0928 06:15:02.212387368      13 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0928 06:15:02.212390190      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD0928 06:15:02.212417873      13 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0928 06:15:02.212432757      13 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD0928 06:15:02.212447805      13 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0928 06:15:02.212467538      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0928 06:15:02.212474401      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0928 06:15:02.212477509      13 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0928 06:15:02.212481491      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0928 06:15:02.212484453      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0928 06:15:02.212487477      13 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0928 06:15:02.212493340      13 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD0928 06:15:02.212522547      13 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI0928 06:15:02.214273761      13 ev_epoll1_linux.cc:359]               grpc epoll fd: 62\nI0928 06:15:02.222999703      13 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI0928 06:15:02.232911299     178 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI0928 06:15:02.232964954     178 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0928 06:15:02.238851303     171 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2024-09-28T06:15:02.238834929+00:00\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"print('Running on TPU ', TPU.master())\nexcept ValueError:\n    print('Running on GPU')\n    TPU = None\n\nif TPU:\n    IS_TPU = True\n    tf.config.experimental_connect_to_cluster(TPU)\"\"\"\n\n# detect TPUs\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.TPUStrategy(tpu)\n\nprint(\"Number of accelerators: \", tpu_strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T06:15:15.702631Z","iopub.execute_input":"2024-09-28T06:15:15.703717Z","iopub.status.idle":"2024-09-28T06:15:24.204468Z","shell.execute_reply.started":"2024-09-28T06:15:15.703673Z","shell.execute_reply":"2024-09-28T06:15:24.203663Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1727504119.638172      13 service.cc:145] XLA service 0x5b738e7fe240 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1727504119.638249      13 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1727504119.638253      13 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1727504119.638257      13 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1727504119.638261      13 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1727504119.638264      13 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1727504119.638267      13 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1727504119.638270      13 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1727504119.638273      13 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nNumber of accelerators:  8\n","output_type":"stream"}]},{"cell_type":"code","source":"def read_and_parse_dicom_files_tensorflow_train(full_file_path):\n    #tf.config.run_functions_eagerly(True)\n    raw_image = tf.io.read_file(full_file_path)\n    sp = tf.strings.split(tf.gather(tf.strings.split(full_file_path, 'images/'), 1), '/')\n    N = tf.size(sp)\n    LEN = tf.strings.length(tf.gather(sp, 0))+tf.strings.length(tf.gather(sp, 2))\n    \n    # Add missing file metadata to avoid warnnigs flooding\n    if   LEN==12: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x92\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==13: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x92\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==14: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x94\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==15: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x94\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==16: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x96\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==17: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x96\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==18: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x98\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    \n    image = tfio.image.decode_dicom_image(raw_image, scale='auto', dtype=tf.float32)\n    m, M=tf.math.reduce_min(image), tf.math.reduce_max(image)\n    image = (tf.image.grayscale_to_rgb(image)-m)/(M-m)\n    image = tf.image.resize(image, (128,128))\n    sqzd_image = tf.squeeze(image)\n    #shaped_image = sqzd_image.set_shape(sqzd_image.get_shape())\n    return sqzd_image\n\ndef preprocessing(img_path):\n    train_img = read_and_parse_dicom_files_tensorflow_train(img_path)\n    train_img = tf.reshape(train_img, shape=(128, 128, 3))\n    return train_img\n\ndef load_dataset_tensorflow_train(image_path, labels):\n    image = preprocessing(image_path)\n    return {\"images\": tf.cast(image, tf.float32), \"labels\": tf.cast(labels, tf.float32)}\n\ndef dict_to_tuple(inputs):\n    return inputs[\"images\"], inputs[\"labels\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-28T06:15:35.615406Z","iopub.execute_input":"2024-09-28T06:15:35.616398Z","iopub.status.idle":"2024-09-28T06:15:35.626800Z","shell.execute_reply.started":"2024-09-28T06:15:35.616353Z","shell.execute_reply":"2024-09-28T06:15:35.625941Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"condition_for_training = 'left_neural_foraminal_narrowing'\nvertebrae_position = 'l1_l2'\n\nmetadata_file_path = '/kaggle/input/left-neural-foraminal-narrowing-metadata/{0}_{1}_feature_metadata.csv'.format(condition_for_training, vertebrae_position)\nmetadata_df = pl.read_csv(metadata_file_path, low_memory=True)\n\nx_train, x_test_val = train_test_split(metadata_df, test_size=0.4, random_state=42)\nx_test, x_valid = train_test_split(x_test_val, test_size=0.2, random_state=42)\n\nprint(\"Training data shape : {0}\".format(x_train.shape))\nprint(\"Test data shape : {0}\".format(x_test.shape))\nprint(\"Validation data shape : {0}\".format(x_valid.shape))","metadata":{"execution":{"iopub.status.busy":"2024-09-28T06:15:39.025900Z","iopub.execute_input":"2024-09-28T06:15:39.027002Z","iopub.status.idle":"2024-09-28T06:15:39.357343Z","shell.execute_reply.started":"2024-09-28T06:15:39.026965Z","shell.execute_reply":"2024-09-28T06:15:39.356066Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Training data shape : (88249, 3)\nTest data shape : (47067, 3)\nValidation data shape : (11767, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_image_filenames = pl.Series(x_train.select(pl.col('full_img_path'))).to_list()\ntrain_image_labels = pl.Series(x_train.select(pl.col('encoded_severity'))).to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trial_img = read_and_parse_dicom_files_tensorflow_train(train_image_filenames[0])\nprep_img = preprocessing(train_image_filenames[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#trial_img.get_shape()\n\"\"\"shaped_img = trial_img.set_shape(trial_img.get_shape())\ntype(shaped_img)\"\"\"\n\n\"\"\"t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\ntf.rank(t)\"\"\"\n\ntf.rank(prep_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((train_image_filenames, train_image_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = train_dataset.map(load_dataset_tensorflow_train, num_parallel_calls=tf.data.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_tf_datasets(p_train_df, p_test_df, p_valid_df, p_BATCH_SIZE_PER_REPLICA):\n\n    BATCH_SIZE = p_BATCH_SIZE_PER_REPLICA * tpu_strategy.num_replicas_in_sync\n    \n    train_image_filenames = pl.Series(p_train_df.select(pl.col('full_img_path'))).to_list()\n    train_image_labels = pl.Series(p_train_df.select(pl.col('encoded_severity'))).to_list()\n\n    test_image_filenames = pl.Series(p_test_df.select(pl.col('full_img_path'))).to_list()\n    test_image_labels = pl.Series(p_test_df.select(pl.col('encoded_severity'))).to_list()\n\n    valid_image_filenames = pl.Series(p_valid_df.select(pl.col('full_img_path'))).to_list()\n    valid_image_labels = pl.Series(p_valid_df.select(pl.col('encoded_severity'))).to_list()\n    \n    \n    train_dataset = tf.data.Dataset.from_tensor_slices((train_image_filenames, train_image_labels))\n    test_dataset = tf.data.Dataset.from_tensor_slices((test_image_filenames, test_image_labels))\n    valid_dataset = tf.data.Dataset.from_tensor_slices((valid_image_filenames, valid_image_labels))\n    \n    train_ds = train_dataset.map(load_dataset_tensorflow_train, num_parallel_calls=tf.data.AUTOTUNE)\n    train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n    train_ds = train_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n\n    test_ds = test_dataset.map(load_dataset_tensorflow_train, num_parallel_calls=tf.data.AUTOTUNE)\n    test_ds = test_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n    test_ds = test_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n    test_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n\n    valid_ds = valid_dataset.map(load_dataset_tensorflow_train, num_parallel_calls=tf.data.AUTOTUNE)\n    valid_ds = valid_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n    valid_ds = valid_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n    valid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)\n    \n    return train_ds, test_ds, valid_ds","metadata":{"execution":{"iopub.status.busy":"2024-09-28T06:16:03.601329Z","iopub.execute_input":"2024-09-28T06:16:03.602418Z","iopub.status.idle":"2024-09-28T06:16:03.610970Z","shell.execute_reply.started":"2024-09-28T06:16:03.602378Z","shell.execute_reply":"2024-09-28T06:16:03.610024Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_ds, test_ds, valid_ds = generate_tf_datasets(p_train_df=x_train, p_test_df=x_test, p_valid_df=x_valid\n                                                   , p_BATCH_SIZE_PER_REPLICA = 16)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T06:16:05.161337Z","iopub.execute_input":"2024-09-28T06:16:05.161714Z","iopub.status.idle":"2024-09-28T06:16:07.712302Z","shell.execute_reply.started":"2024-09-28T06:16:05.161683Z","shell.execute_reply":"2024-09-28T06:16:07.711202Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras import layers\n\nwith tpu_strategy.scope():\n    \n    rsna_input = layers.Input(shape=(128,128,3), name=\"rsna_input\")\n\n    conv_base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=rsna_input)\n    conv_base.trainable = False\n\n    max_pool_layer_0 = layers.MaxPooling2D(name=\"max_pool_0\", pool_size=(2, 2), strides=(1, 1), padding=\"same\")(conv_base.output)\n    max_pool_layer_0 = layers.BatchNormalization()(max_pool_layer_0)\n\n    conv2d_1 = layers.Conv2D(filters=100, kernel_size=4, strides=1, padding=\"same\", activation=\"relu\")(max_pool_layer_0)\n    max_pool_layer_1 = layers.MaxPooling2D(name=\"max_pool_1\", pool_size=(2, 2), strides=(1, 1), padding=\"same\")(conv2d_1)\n    max_pool_layer_1 = layers.BatchNormalization()(max_pool_layer_1)\n\n    flattened_layer = layers.Flatten()(max_pool_layer_1)\n\n    hidden_layer1 = layers.Dense(200, activation=\"selu\", kernel_initializer=keras.initializers.LecunNormal(seed=None))(flattened_layer)\n    hidden_layer1 = layers.BatchNormalization()(hidden_layer1)\n    hidden_layer2 = layers.Dense(100, activation=\"selu\", kernel_initializer=keras.initializers.LecunNormal(seed=None))(hidden_layer1)\n    hidden_layer2 = layers.BatchNormalization()(hidden_layer2)\n    hidden_layer3 = layers.Dense(50, activation=\"selu\", kernel_initializer=keras.initializers.LecunNormal(seed=None))(hidden_layer2)\n    hidden_layer3 = layers.BatchNormalization()(hidden_layer3)\n    rsna_output = layers.Dense(3, activation=\"softmax\")(hidden_layer3)\n    model = tf.keras.Model(rsna_input, rsna_output)\n\n    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"keras_effnet_{0}_{1}.keras\".format(condition_for_training, vertebrae_position))\n    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n\n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adamax\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T06:16:11.778415Z","iopub.execute_input":"2024-09-28T06:16:11.779098Z","iopub.status.idle":"2024-09-28T06:16:30.210714Z","shell.execute_reply.started":"2024-09-28T06:16:11.779062Z","shell.execute_reply":"2024-09-28T06:16:30.209678Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"I0000 00:00:1727504171.856667      13 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"with tpu_strategy.scope():\n    history = model.fit(train_ds, class_weight={0:2, 1:1, 2:4}, epochs=7, validation_data=valid_ds\n                        , callbacks=[checkpoint_cb, early_stopping_cb])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T06:19:43.323615Z","iopub.execute_input":"2024-09-28T06:19:43.324799Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/7\n","output_type":"stream"},{"name":"stderr","text":"2024-09-28 06:19:51.150471: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.\nI0000 00:00:1727504392.057317     840 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(f126606dc486d6b8:0:0), session_name()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  4/689\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - accuracy: 0.9388 - loss: 0.4622   ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727504409.508687     840 tpu_compile_op_common.cc:245] Compilation of f126606dc486d6b8:0:0 with session name  took 17.451326141s and succeeded\nI0000 00:00:1727504409.577881     840 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(f126606dc486d6b8:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_iterator_6473348430844852907\", property.function_library_fingerprint = 13904576599489135420, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727504409.577940     840 tpu_compilation_cache_interface.cc:541] After adding entry for key f126606dc486d6b8:0:0 with session_name  cache is 3 entries (156701486 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m687/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9627 - loss: 0.2935","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727504440.006501     835 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(b48def31d20c9421:0:0), session_name()\nI0000 00:00:1727504443.841619     835 tpu_compile_op_common.cc:245] Compilation of b48def31d20c9421:0:0 with session name  took 3.835072264s and succeeded\nI0000 00:00:1727504443.856279     835 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(b48def31d20c9421:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_iterator_8690839742036917094\", property.function_library_fingerprint = 9047313440813943844, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727504443.856311     835 tpu_compilation_cache_interface.cc:541] After adding entry for key b48def31d20c9421:0:0 with session_name  cache is 4 entries (174676830 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 56ms/step - accuracy: 0.9627 - loss: 0.2935 - val_accuracy: 0.9636 - val_loss: 0.1828\nEpoch 2/7\n\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 49ms/step - accuracy: 0.9627 - loss: 0.2821 - val_accuracy: 0.9636 - val_loss: 0.1729\nEpoch 3/7\n\u001b[1m475/689\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - accuracy: 0.9618 - loss: 0.2840","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}