{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":109139,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":83858,"modelId":108105}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\n# import polars as pl\n# import duckdb as dd\nfrom tqdm import tqdm\n\"\"\"import matplotlib.pyplot as plt\nimport cv2\nfrom pydicom import dcmread\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\nimport gc\nimport ctypes\"\"\"\n# from sklearn.model_selection import train_test_split\nimport tensorflow as tf\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\nimport tensorflow_io as tfio\nfrom tensorflow import keras\nfrom tensorflow.python.keras import backend as K\nfrom joblib import Parallel, delayed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-26T07:13:17.521651Z","iopub.execute_input":"2024-08-26T07:13:17.522585Z","iopub.status.idle":"2024-08-26T07:13:32.751054Z","shell.execute_reply.started":"2024-08-26T07:13:17.522534Z","shell.execute_reply":"2024-08-26T07:13:32.749916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntry: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T07:13:42.338002Z","iopub.execute_input":"2024-08-26T07:13:42.338666Z","iopub.status.idle":"2024-08-26T07:13:43.847870Z","shell.execute_reply.started":"2024-08-26T07:13:42.338617Z","shell.execute_reply":"2024-08-26T07:13:43.846915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test = False\nconfig = {}\n\nif Test:\n    config['root_file_path'] = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\n    config['start'] = 10\n    config['end'] = 460\n    studies = os.listdir(config['root_file_path'])[config['start']:config['end']]\n    #studies = os.listdir(config['root_file_path'])\n    test_dict = {}\nelse:\n    config['root_file_path'] = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/'\n    studies = os.listdir(config['root_file_path'])\n    test_dict = {}\n    \nfor study in studies:\n    image_files = []\n    for dirname, _, filenames in os.walk(config['root_file_path']+'/'+study):\n        for filename in filenames:\n            test_dict[os.path.join(dirname, filename).split('/')[-3]] = image_files\n            image_files.append(os.path.join(dirname, filename))\n            \nprint(len(test_dict))","metadata":{"execution":{"iopub.status.busy":"2024-08-26T07:13:46.510672Z","iopub.execute_input":"2024-08-26T07:13:46.511521Z","iopub.status.idle":"2024-08-26T07:13:46.562863Z","shell.execute_reply.started":"2024-08-26T07:13:46.511476Z","shell.execute_reply":"2024-08-26T07:13:46.561995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"for st in test_dict.keys():\n    print(\"number of images in the study {0} : {1}\".format(st, len(test_dict[st])))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-26T04:49:36.770942Z","iopub.execute_input":"2024-08-26T04:49:36.771685Z","iopub.status.idle":"2024-08-26T04:49:36.799853Z","shell.execute_reply.started":"2024-08-26T04:49:36.771642Z","shell.execute_reply":"2024-08-26T04:49:36.798812Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from multiprocessing import cpu_count\nn_cores = cpu_count()\nprint(f'Number of Logical CPU cores: {n_cores}')","metadata":{"execution":{"iopub.status.busy":"2024-08-26T07:13:51.653527Z","iopub.execute_input":"2024-08-26T07:13:51.654350Z","iopub.status.idle":"2024-08-26T07:13:51.659302Z","shell.execute_reply.started":"2024-08-26T07:13:51.654311Z","shell.execute_reply":"2024-08-26T07:13:51.658415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"model = keras.models.\\\nload_model(\"/kaggle/input/keras_base_scs_l1_l2/tensorflow2/default/2/keras_base_spinal_canal_stenosis_l1_l2.h5\")\"\"\"\n\nmodel_dict['spinal_canal_stenosis_l1_l2'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_scs_l1_l2/tensorflow2/default/2/keras_base_spinal_canal_stenosis_l1_l2.h5\")\n\nmodel_dict['spinal_canal_stenosis_l2_l3'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_spinal_canal_stenosis_l2_l3/tensorflow2/default/1/keras_base_spinal_canal_stenosis_l2_l3.h5\")\n\nmodel_dict['spinal_canal_stenosis_l3_l4'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_spinal_canal_stenosis_l3_l4/tensorflow2/default/1/keras_base_spinal_canal_stenosis_l3_l4.h5\")\n\nmodel_dict['spinal_canal_stenosis_l4_l5'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_spinal_canal_stenosis_l4_l5/tensorflow2/default/1/keras_base_spinal_canal_stenosis_l4_l5.h5\")\n\nmodel_dict['spinal_canal_stenosis_l5_s1'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_spinal_canal_stenosis_l5_s1/tensorflow2/default/1/keras_base_spinal_canal_stenosis_l5_s1.h5\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-26T07:13:54.052637Z","iopub.execute_input":"2024-08-26T07:13:54.053536Z","iopub.status.idle":"2024-08-26T07:13:56.399215Z","shell.execute_reply.started":"2024-08-26T07:13:54.053494Z","shell.execute_reply":"2024-08-26T07:13:56.398409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_and_parse_dicom_files_for_inf(full_file_path):\n    tf.config.run_functions_eagerly(True)\n    raw_image = tf.io.read_file(full_file_path)\n    sp = tf.strings.split(tf.gather(tf.strings.split(full_file_path, 'images/'), 1), '/')\n    N = tf.size(sp)\n    LEN = tf.strings.length(tf.gather(sp, 0))+tf.strings.length(tf.gather(sp, 2))\n    \n    # Add missing file metadata to avoid warnnigs flooding\n    if   LEN==12: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x92\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==13: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x92\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==14: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x94\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==15: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x94\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==16: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x96\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==17: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x96\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==18: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x98\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    \n    #image_bytes = tf.io.read_file(full_file_path)\n    #image = tfio.image.decode_dicom_image(image_bytes, scale='auto', dtype=tf.float32)\n    image = tfio.image.decode_dicom_image(raw_image, scale='auto', dtype=tf.float32)\n    m, M=tf.math.reduce_min(image), tf.math.reduce_max(image)\n    image = (tf.image.grayscale_to_rgb(image)-m)/(M-m)\n    image = tf.image.resize(image, (128,128))\n    return tf.squeeze(image)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T07:13:58.564663Z","iopub.execute_input":"2024-08-26T07:13:58.565398Z","iopub.status.idle":"2024-08-26T07:13:58.576750Z","shell.execute_reply.started":"2024-08-26T07:13:58.565353Z","shell.execute_reply":"2024-08-26T07:13:58.575568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vfunc = np.vectorize(read_and_parse_dicom_files_for_inf, otypes=[object])\n\ndef get_predictions(key, model_to_use):\n    final_feature_list = vfunc(test_dict[key]).tolist()\n    final = np.array(final_feature_list)\n    return model_to_use.predict(final)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T07:14:02.100693Z","iopub.execute_input":"2024-08-26T07:14:02.101685Z","iopub.status.idle":"2024-08-26T07:14:02.106589Z","shell.execute_reply.started":"2024-08-26T07:14:02.101633Z","shell.execute_reply":"2024-08-26T07:14:02.105606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = {}\n#with strategy.scope():\nif Test:\n    for key, value in model_dict.items():\n        y_proba = [get_predictions(st, model_dict[key]) for st in tqdm(test_dict.keys())] ## 27 min with 2 GPUs; not under strategy\n        for i in range(len(y_proba)):\n            rows[list(test_dict.keys())[i]+'_'+key] = np.mean(y_proba[i], axis=0)\nelse:\n    #y_proba = [get_predictions(st, model) for st in test_dict.keys()]\n    for key, value in model_dict.items():\n        y_proba = [get_predictions(st, model_dict[key]) for st in test_dict.keys()] ## 27 min with 2 GPUs; not under strategy\n        for i in range(len(y_proba)):\n            rows[list(test_dict.keys())[i]+'_'+key] = np.mean(y_proba[i], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T07:14:06.608886Z","iopub.execute_input":"2024-08-26T07:14:06.609271Z","iopub.status.idle":"2024-08-26T07:14:15.606389Z","shell.execute_reply.started":"2024-08-26T07:14:06.609233Z","shell.execute_reply":"2024-08-26T07:14:15.605570Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_proba = (Parallel(n_jobs=90)(delayed(get_predictions)(st, model) for st in tqdm(test_dict.keys())))","metadata":{"execution":{"iopub.status.busy":"2024-08-26T04:57:27.513092Z","iopub.execute_input":"2024-08-26T04:57:27.513741Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = {}\n\nfor i in range(len(y_proba)):\n    rows[list(test_dict.keys())[i]+'_spinal_canal_stenosis_l1_l2'] = np.mean(y_proba[i], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T05:40:31.477557Z","iopub.execute_input":"2024-08-26T05:40:31.477954Z","iopub.status.idle":"2024-08-26T05:40:31.485914Z","shell.execute_reply.started":"2024-08-26T05:40:31.477915Z","shell.execute_reply":"2024-08-26T05:40:31.484891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv')\nsubmission['row_id'] = 'samples'","metadata":{"execution":{"iopub.status.busy":"2024-08-26T05:41:31.648494Z","iopub.execute_input":"2024-08-26T05:41:31.649316Z","iopub.status.idle":"2024-08-26T05:41:31.658348Z","shell.execute_reply.started":"2024-08-26T05:41:31.649276Z","shell.execute_reply":"2024-08-26T05:41:31.657365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# weight_dict = {'normal_mild':1, 'moderate':2, 'severe':4}\nconditions = ['spinal_canal_stenosis', 'neural_foraminal_narrowing', 'subarticular_stenosis']\nsides = ['left', 'right']\nvertebrae_levels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\nseverity_levels = ['normal_mild', 'moderate', 'severe']\n\nfor c in conditions:\n    for v in vertebrae_levels:\n        if c != 'spinal_canal_stenosis':\n            for s in sides:\n                for st in test_dict.keys():\n                    rows[st+'_'+s+'_'+c+'_'+v] = np.array([0.555555, 0.222222, 0.222222])\n        else:\n            for st in test_dict.keys():\n                if c+'_'+v == 'spinal_canal_stenosis_l1_l2':\n                    pass\n                else:\n                    rows[st+'_'+c+'_'+v] = np.array([0.555555, 0.222222, 0.222222])","metadata":{"execution":{"iopub.status.busy":"2024-08-26T05:40:36.741589Z","iopub.execute_input":"2024-08-26T05:40:36.742243Z","iopub.status.idle":"2024-08-26T05:40:36.750055Z","shell.execute_reply.started":"2024-08-26T05:40:36.742199Z","shell.execute_reply":"2024-08-26T05:40:36.748902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if Test:\n    for row_id, feature in tqdm(rows.items()):\n        feature_set_reshaped = feature.reshape(1, -1)\n        predictions = np.ascontiguousarray(feature_set_reshaped)\n        df = pd.DataFrame(predictions, columns=severity_levels)\n        df.insert(loc=0, column='row_id', value=row_id)\n        submission = pd.concat([submission,df]).reset_index(drop=True)\n\n    i = submission[(submission.row_id == 'samples')].index\n    submission = submission.drop(i).reset_index(drop=True)\nelse:\n    for row_id, feature in rows.items():\n        feature_set_reshaped = feature.reshape(1, -1)\n        predictions = np.ascontiguousarray(feature_set_reshaped)\n        df = pd.DataFrame(predictions, columns=severity_levels)\n        df.insert(loc=0, column='row_id', value=row_id)\n        submission = pd.concat([submission,df]).reset_index(drop=True)\n\n    i = submission[(submission.row_id == 'samples')].index\n    submission = submission.drop(i).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T05:41:35.331302Z","iopub.execute_input":"2024-08-26T05:41:35.332154Z","iopub.status.idle":"2024-08-26T05:41:35.362913Z","shell.execute_reply.started":"2024-08-26T05:41:35.332110Z","shell.execute_reply":"2024-08-26T05:41:35.362079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T05:41:52.314106Z","iopub.execute_input":"2024-08-26T05:41:52.315071Z","iopub.status.idle":"2024-08-26T05:41:52.320771Z","shell.execute_reply.started":"2024-08-26T05:41:52.315029Z","shell.execute_reply":"2024-08-26T05:41:52.319750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}