{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":109139,"sourceType":"modelInstanceVersion","modelInstanceId":83858,"modelId":108105},{"sourceId":109574,"sourceType":"modelInstanceVersion","modelInstanceId":91762,"modelId":115977},{"sourceId":117800,"sourceType":"modelInstanceVersion","modelInstanceId":99040,"modelId":123206},{"sourceId":117802,"sourceType":"modelInstanceVersion","modelInstanceId":99041,"modelId":123207},{"sourceId":117803,"sourceType":"modelInstanceVersion","modelInstanceId":99042,"modelId":123208},{"sourceId":117804,"sourceType":"modelInstanceVersion","modelInstanceId":99043,"modelId":123209},{"sourceId":117805,"sourceType":"modelInstanceVersion","modelInstanceId":99044,"modelId":123210},{"sourceId":118273,"sourceType":"modelInstanceVersion","modelInstanceId":91765,"modelId":115980},{"sourceId":118318,"sourceType":"modelInstanceVersion","modelInstanceId":91764,"modelId":115979},{"sourceId":121067,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":91763,"modelId":115978}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport polars as pl\n# import duckdb as dd\nfrom tqdm import tqdm\nfrom itertools import product\n\"\"\"import matplotlib.pyplot as plt\nimport cv2\nfrom pydicom import dcmread\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\nimport gc\nimport ctypes\"\"\"\n# from sklearn.model_selection import train_test_split\nimport tensorflow as tf\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\nimport tensorflow_io as tfio\nfrom tensorflow import keras\nfrom tensorflow.python.keras import backend as K\nfrom joblib import Parallel, delayed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-28T17:13:21.900717Z","iopub.execute_input":"2024-09-28T17:13:21.901143Z","iopub.status.idle":"2024-09-28T17:13:38.184297Z","shell.execute_reply.started":"2024-09-28T17:13:21.901092Z","shell.execute_reply":"2024-09-28T17:13:38.183192Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\"\"\"try: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    \nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encoder(label):\n    if label == 'Normal/Mild':\n        return 2\n    elif label == 'Severe':\n        return 3\n    else:\n        return 1\n    \ndef attach_weights(label):\n    if label == 'Normal/Mild':\n        return 1\n    elif label == 'Severe':\n        return 4\n    else:\n        return 2\n    \ndef get_condition(full_location: str) -> str:\n    # Given an input like spinal_canal_stenosis_l1_l2 extracts 'spinal'\n    for injury_condition in ['spinal', 'foraminal', 'subarticular']:\n        if injury_condition in full_location:\n            return injury_condition\n    raise ValueError(f'condition not found in {full_location}')","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:13:42.634382Z","iopub.execute_input":"2024-09-28T17:13:42.635144Z","iopub.status.idle":"2024-09-28T17:13:42.643665Z","shell.execute_reply.started":"2024-09-28T17:13:42.635096Z","shell.execute_reply":"2024-09-28T17:13:42.642330Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"Test = True\nconfig = {}\n\nif Test:\n    config['root_file_path'] = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\n    config['start'] = 10\n    config['end'] = 30\n    \n    train_studies_metadata_file_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv'\n    train_studies_metadata_df = pl.read_csv(train_studies_metadata_file_path, low_memory=True)\n    print(\"before dropping nulls :\", train_studies_metadata_df.shape)\n    train_studies_metadata_df = train_studies_metadata_df.drop_nulls()\n    print(\"after dropping nulls :\", train_studies_metadata_df.shape)\n\n    studies_full = train_studies_metadata_df.select(pl.col('study_id')).unique().to_series().to_list()\n    print(\"total number of studies : \", len(studies_full))\n    \n    studies = studies_full[config['start']:config['end']]\n    #studies = os.listdir(config['root_file_path'])\n    test_dict = {}\nelse:\n    config['root_file_path'] = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/'\n    studies = os.listdir(config['root_file_path'])\n    test_dict = {}\n    \nfor study in studies:\n    image_files = []\n    for dirname, _, filenames in os.walk(config['root_file_path']+'/'+str(study)):\n        for filename in filenames:\n            test_dict[os.path.join(dirname, filename).split('/')[-3]] = image_files\n            image_files.append(os.path.join(dirname, filename))\n            \nprint(len(test_dict))","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:13:54.699403Z","iopub.execute_input":"2024-09-28T17:13:54.700299Z","iopub.status.idle":"2024-09-28T17:13:55.533300Z","shell.execute_reply.started":"2024-09-28T17:13:54.700245Z","shell.execute_reply":"2024-09-28T17:13:55.531961Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"before dropping nulls : (1975, 26)\nafter dropping nulls : (1790, 26)\ntotal number of studies :  1790\n20\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_solution_df(run_config, run_test_dict):\n\n    print(\"total number of run_test_dict items : \",len(run_test_dict))\n    \n    train_studies_metadata_df_up = train_studies_metadata_df.unpivot(index=\"study_id\")\n    train_studies_metadata_df_up.columns = ['study_id', 'condition', 'severity']\n\n    train_studies_metadata_df_up = train_studies_metadata_df_up.with_columns([\n        pl.col(\"severity\").map_elements(label_encoder, return_dtype=pl.Int32).alias(\"encoded_severity\"),\n        pl.col(\"severity\").map_elements(attach_weights, return_dtype=pl.Int32).alias(\"sample_weight\"),\n        (pl.col(\"study_id\").cast(pl.String)+'_'+pl.col(\"condition\")).alias(\"row_id\")\n    ])\n\n    print(\"train_studies_metadata_df_up shape : \",train_studies_metadata_df_up.shape)\n    \n    temp = train_studies_metadata_df_up.select([pl.col('study_id'), pl.col('row_id'), pl.col('encoded_severity'), pl.col('severity'), pl.col('sample_weight')])\n    train_studies_metadata_df_final = temp.pivot(\"severity\", index=[\"study_id\",\"row_id\"], values=\"encoded_severity\")\n    train_studies_metadata_df_final.columns = ['study_id', 'row_id', 'normal_mild', 'moderate', 'severe']\n    \n    train_studies_metadata_df_final_2 = train_studies_metadata_df_final.join(temp, on=[\"study_id\",\"row_id\"], how=\"inner\")\n    train_studies_metadata_df_final_2 = train_studies_metadata_df_final_2.drop(['encoded_severity', 'severity'])\n    train_studies_metadata_df_final_2 = train_studies_metadata_df_final_2.with_columns([\n        pl.when(pl.col('normal_mild').is_not_null()).then(1).otherwise(0).alias('true_normal_mild'),\n        pl.when(pl.col('moderate').is_not_null()).then(1).otherwise(0).alias('true_moderate'),\n        pl.when(pl.col('severe').is_not_null()).then(1).otherwise(0).alias('true_severe'),\n    ])\n    \n    train_studies_metadata_df_final_2 = train_studies_metadata_df_final_2.drop(['normal_mild', 'moderate', 'severe'])\n    train_studies_metadata_df_final_2.columns = ['study_id', 'row_id', 'sample_weight', 'normal_mild', 'moderate', 'severe']\n    \n    solutions = train_studies_metadata_df_final_2.filter(pl.col('study_id').is_in(studies))\n    solutions = solutions.drop(['study_id'])\n    print(\"shape of solutions dataframe : \", solutions.shape)\n    \n    return solutions.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:14:00.010005Z","iopub.execute_input":"2024-09-28T17:14:00.010452Z","iopub.status.idle":"2024-09-28T17:14:00.026197Z","shell.execute_reply.started":"2024-09-28T17:14:00.010410Z","shell.execute_reply":"2024-09-28T17:14:00.024467Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import log_loss\n\ndef calculate_final_score(solution_df, submission_df):\n    \n    target_levels = ['normal_mild', 'moderate', 'severe']\n\n    if not pd.api.types.is_numeric_dtype(submission_df[target_levels].values):\n            raise ParticipantVisibleError('All submission_df values must be numeric')\n\n    if not np.isfinite(submission_df[target_levels].values).all():\n        raise ParticipantVisibleError('All submission_df values must be finite')\n\n    if solution_df[target_levels].min().min() < 0:\n        raise ParticipantVisibleError('All labels must be at least zero')\n    if submission_df[target_levels].min().min() < 0:\n        raise ParticipantVisibleError('All predictions must be at least zero')\n        \n    solution_df['study_id'] = solution_df['row_id'].apply(lambda x: x.split('_')[0])\n    solution_df['location'] = solution_df['row_id'].apply(lambda x: '_'.join(x.split('_')[1:]))\n    solution_df['condition'] = solution_df['row_id'].apply(get_condition)\n    \n    row_id_column_name = 'row_id'\n\n    del solution_df[row_id_column_name]\n    del submission_df[row_id_column_name]\n    assert sorted(submission_df.columns) == sorted(target_levels)\n\n    submission_df['study_id'] = solution_df['study_id']\n    submission_df['location'] = solution_df['location']\n    submission_df['condition'] = solution_df['condition']\n    \n    condition_losses = []\n    condition_weights = []\n    \n    for condition in ['spinal', 'foraminal', 'subarticular']:\n        condition_indices = solution_df.loc[solution_df['condition'] == condition].index.values\n        condition_loss = log_loss(\n            y_true=solution_df.loc[condition_indices, target_levels].values,\n            y_pred=submission_df.loc[condition_indices, target_levels].values,\n            sample_weight=solution_df.loc[condition_indices, 'sample_weight'].values\n        )\n        condition_losses.append(condition_loss)\n        condition_weights.append(1)\n        \n    any_severe_spinal_labels = pd.Series(solution_df.loc[solution_df['condition'] == 'spinal'].groupby('study_id')['severe'].max())\n    any_severe_spinal_weights = pd.Series(solution_df.loc[solution_df['condition'] == 'spinal'].groupby('study_id')['sample_weight'].max())\n    any_severe_spinal_predictions = pd.Series(submission_df.loc[submission_df['condition'] == 'spinal'].groupby('study_id')['severe'].max())\n    \n    any_severe_scalar = 1.0\n\n    any_severe_spinal_loss = log_loss(\n        y_true=any_severe_spinal_labels,\n        y_pred=any_severe_spinal_predictions,\n        sample_weight=any_severe_spinal_weights\n    )\n    condition_losses.append(any_severe_spinal_loss)\n    condition_weights.append(any_severe_scalar)\n\n    print(\"final score during training : \", np.average(condition_losses, weights=condition_weights))\n    \n    return np.average(condition_losses, weights=condition_weights)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:14:04.987536Z","iopub.execute_input":"2024-09-28T17:14:04.988229Z","iopub.status.idle":"2024-09-28T17:14:05.554019Z","shell.execute_reply.started":"2024-09-28T17:14:04.988183Z","shell.execute_reply":"2024-09-28T17:14:05.552741Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if Test:\n    solution_data = create_solution_df(config, test_dict)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:14:09.138154Z","iopub.execute_input":"2024-09-28T17:14:09.138933Z","iopub.status.idle":"2024-09-28T17:14:09.323498Z","shell.execute_reply.started":"2024-09-28T17:14:09.138884Z","shell.execute_reply":"2024-09-28T17:14:09.322394Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"total number of run_test_dict items :  20\ntrain_studies_metadata_df_up shape :  (44750, 6)\nshape of solutions dataframe :  (500, 5)\n","output_type":"stream"}]},{"cell_type":"code","source":"from multiprocessing import cpu_count\nn_cores = cpu_count()\nprint(f'Number of Logical CPU cores: {n_cores}')","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:14:17.839573Z","iopub.execute_input":"2024-09-28T17:14:17.840055Z","iopub.status.idle":"2024-09-28T17:14:17.846827Z","shell.execute_reply.started":"2024-09-28T17:14:17.840004Z","shell.execute_reply":"2024-09-28T17:14:17.845399Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Number of Logical CPU cores: 4\n","output_type":"stream"}]},{"cell_type":"code","source":"model_dict = {}\n\n\"\"\"model_dict['right_neural_foraminal_narrowing_l1_l2'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_right_neural_foraminal_narrowing_l1_l2/tensorflow2/default/1/keras_base_right_neural_foraminal_narrowing_l1_l2.h5\")\n\nmodel_dict['right_neural_foraminal_narrowing_l2_l3'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_right_neural_foraminal_narrowing_l2_l3/tensorflow2/default/1/keras_base_right_neural_foraminal_narrowing_l2_l3.h5\")\n\nmodel_dict['right_neural_foraminal_narrowing_l3_l4'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_right_neural_foraminal_narrowing_l3_l4/tensorflow2/default/1/keras_base_right_neural_foraminal_narrowing_l3_l4.h5\")\n\nmodel_dict['right_neural_foraminal_narrowing_l4_l5'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_right_neural_foraminal_narrowing_l4_l5/tensorflow2/default/1/keras_base_right_neural_foraminal_narrowing_l4_l5.h5\")\n\nmodel_dict['right_neural_foraminal_narrowing_l5_s1'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_right_neural_foraminal_narrowing_l5_s1/tensorflow2/default/1/keras_base_right_neural_foraminal_narrowing_l5_s1.h5\")\n\nmodel_dict['spinal_canal_stenosis_l1_l2'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_scs_l1_l2/tensorflow2/default/2/keras_base_spinal_canal_stenosis_l1_l2.h5\")\n\nmodel_dict['spinal_canal_stenosis_l2_l3'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_spinal_canal_stenosis_l2_l3/tensorflow2/default/1/keras_base_spinal_canal_stenosis_l2_l3.h5\")\n\"\"\"\n\nmodel_dict['left_neural_foraminal_narrowing_l1_l2'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_left_neural_foraminal_narrowing_l1_l2/tensorflow2/default/2/keras_base_left_neural_foraminal_narrowing_l1_l2.h5\")\n\n\"\"\"model_dict['spinal_canal_stenosis_l3_l4'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_spinal_canal_stenosis_l3_l4/tensorflow2/default/2/keras_base_spinal_canal_stenosis_l3_l4.h5\")\"\"\"\n\nmodel_dict['spinal_canal_stenosis_l4_l5'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_spinal_canal_stenosis_l4_l5/tensorflow2/default/2/keras_base_spinal_canal_stenosis_l4_l5.h5\")\n\nmodel_dict['spinal_canal_stenosis_l5_s1'] = keras.models.\\\nload_model(\"/kaggle/input/keras_base_spinal_canal_stenosis_l5_s1/tensorflow2/default/2/keras_base_spinal_canal_stenosis_l5_s1.h5\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:14:20.334930Z","iopub.execute_input":"2024-09-28T17:14:20.335366Z","iopub.status.idle":"2024-09-28T17:14:28.576013Z","shell.execute_reply.started":"2024-09-28T17:14:20.335327Z","shell.execute_reply":"2024-09-28T17:14:28.574434Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def read_and_parse_dicom_files_for_inf(full_file_path):\n    tf.config.run_functions_eagerly(True)\n    raw_image = tf.io.read_file(full_file_path)\n    sp = tf.strings.split(tf.gather(tf.strings.split(full_file_path, 'images/'), 1), '/')\n    N = tf.size(sp)\n    LEN = tf.strings.length(tf.gather(sp, 0))+tf.strings.length(tf.gather(sp, 2))\n    \n    # Add missing file metadata to avoid warnnigs flooding\n    if   LEN==12: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x92\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==13: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x92\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==14: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x94\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==15: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x94\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==16: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x96\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==17: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x96\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==18: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x98\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    \n    #image_bytes = tf.io.read_file(full_file_path)\n    #image = tfio.image.decode_dicom_image(image_bytes, scale='auto', dtype=tf.float32)\n    image = tfio.image.decode_dicom_image(raw_image, scale='auto', dtype=tf.float32)\n    m, M=tf.math.reduce_min(image), tf.math.reduce_max(image)\n    image = (tf.image.grayscale_to_rgb(image)-m)/(M-m)\n    image = tf.image.resize(image, (128,128))\n    return tf.squeeze(image)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:14:32.995927Z","iopub.execute_input":"2024-09-28T17:14:32.996378Z","iopub.status.idle":"2024-09-28T17:14:33.011033Z","shell.execute_reply.started":"2024-09-28T17:14:32.996329Z","shell.execute_reply":"2024-09-28T17:14:33.009737Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"vfunc = np.vectorize(read_and_parse_dicom_files_for_inf, otypes=[object])\n\ndef get_predictions(key, model_to_use):\n    final_feature_list = vfunc(test_dict[key]).tolist()\n    final = np.array(final_feature_list)\n    return model_to_use.predict(final)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:14:35.947758Z","iopub.execute_input":"2024-09-28T17:14:35.948175Z","iopub.status.idle":"2024-09-28T17:14:35.954685Z","shell.execute_reply.started":"2024-09-28T17:14:35.948136Z","shell.execute_reply":"2024-09-28T17:14:35.953187Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Inference With GPU Support","metadata":{}},{"cell_type":"code","source":"\"\"\"rows = {}\nwith strategy.scope():\n    if Test:\n        for key, value in model_dict.items():\n            print(\"running for key :\", key)\n            y_proba = [get_predictions(st, model_dict[key]) for st in tqdm(test_dict.keys())] ## 27 min with 2 GPUs; not under strategy\n            for i in range(len(y_proba)):\n                rows[list(test_dict.keys())[i]+'_'+key] = np.mean(y_proba[i], axis=0)\n    else:\n        #y_proba = [get_predictions(st, model) for st in test_dict.keys()]\n        for key, value in model_dict.items():\n            y_proba = [get_predictions(st, model_dict[key]) for st in test_dict.keys()] ## 27 min with 2 GPUs; not under strategy\n            for i in range(len(y_proba)):\n                rows[list(test_dict.keys())[i]+'_'+key] = np.mean(y_proba[i], axis=0)\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference w/o GPU support using parallel processing","metadata":{}},{"cell_type":"code","source":"key_combo = product(model_dict.keys(), test_dict.keys())\n\nrows = {}\n\nif Test:\n    y_proba = (Parallel(n_jobs=4)(delayed(get_predictions)(tpl[1], model_dict[tpl[0]]) for tpl in tqdm(key_combo)))\n    for key, value in model_dict.items():\n        for i in range(len(y_proba)):\n                rows[list(test_dict.keys())[i%len(test_dict)]+'_'+key] = np.mean(y_proba[i], axis=0)\nelse:\n    y_proba = (Parallel(n_jobs=4)(delayed(get_predictions)(tpl[1], model_dict[tpl[0]]) for tpl in key_combo))\n    for key, value in model_dict.items():\n        for i in range(len(y_proba)):\n                rows[list(test_dict.keys())[i%len(test_dict)]+'_'+key] = np.mean(y_proba[i], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:14:40.966805Z","iopub.execute_input":"2024-09-28T17:14:40.967228Z","iopub.status.idle":"2024-09-28T17:19:14.000783Z","shell.execute_reply.started":"2024-09-28T17:14:40.967188Z","shell.execute_reply":"2024-09-28T17:19:13.999253Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"4it [00:00, 28.70it/s]/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adamax', because it has 42 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adamax', because it has 42 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adamax', because it has 42 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adamax', because it has 42 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: invalid value encountered in read_and_parse_dicom_files_for_inf (vectorized)\n  outputs = ufunc(*inputs)\n/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: invalid value encountered in read_and_parse_dicom_files_for_inf (vectorized)\n  outputs = ufunc(*inputs)\n/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n4it [00:19, 28.70it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3s/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: invalid value encountered in read_and_parse_dicom_files_for_inf (vectorized)\n  outputs = ufunc(*inputs)\n/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2455: RuntimeWarning: invalid value encountered in read_and_parse_dicom_files_for_inf (vectorized)\n  outputs = ufunc(*inputs)\n/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n","output_type":"stream"},{"name":"stderr","text":"8it [00:23,  3.46s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step\n\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step","output_type":"stream"},{"name":"stderr","text":"12it [00:37,  3.42s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step","output_type":"stream"},{"name":"stderr","text":"16it [00:54,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n\u001b[1m4/7\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 2s/step","output_type":"stream"},{"name":"stderr","text":"20it [01:16,  4.37s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step","output_type":"stream"},{"name":"stderr","text":"24it [01:34,  4.41s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adamax', because it has 34 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adamax', because it has 34 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step","output_type":"stream"},{"name":"stderr","text":"28it [01:48,  4.19s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adamax', because it has 34 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adamax', because it has 34 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1s/step","output_type":"stream"},{"name":"stderr","text":"32it [02:05,  4.18s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n","output_type":"stream"},{"name":"stderr","text":"36it [02:22,  4.18s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n\u001b[1m5/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2s/step","output_type":"stream"},{"name":"stderr","text":"40it [02:46,  4.74s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n","output_type":"stream"},{"name":"stderr","text":"44it [02:59,  4.31s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n","output_type":"stream"},{"name":"stderr","text":"48it [03:15,  4.22s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step","output_type":"stream"},{"name":"stderr","text":"52it [03:30,  4.10s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step","output_type":"stream"},{"name":"stderr","text":"56it [03:47,  4.10s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step\n\u001b[1m4/7\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 2s/step","output_type":"stream"},{"name":"stderr","text":"60it [04:08,  4.14s/it]","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 981ms/step\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 758ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Using different parallelism","metadata":{}},{"cell_type":"code","source":"\"\"\"rows = {}\ny_proba = {}\n\nif Test:\n    for key, value in model_dict.items():\n        y_proba[key] = (Parallel(n_jobs=4)(delayed(get_predictions)(st, model_dict[key]) for st in tqdm(test_dict.keys())))\n        for i in range(len(y_proba[key])):\n                rows[list(test_dict.keys())[i%len(test_dict)]+'_'+key] = np.mean(y_proba[key][i], axis=0)\nelse:\n    for key, value in model_dict.items():\n        y_proba[key] = (Parallel(n_jobs=4)(delayed(get_predictions)(st, model_dict[key]) for st in test_dict.keys()))\n        for i in range(len(y_proba[key])):\n                rows[list(test_dict.keys())[i%len(test_dict)]+'_'+key] = np.mean(y_proba[key][i], axis=0)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-09-25T04:24:02.504191Z","iopub.execute_input":"2024-09-25T04:24:02.504661Z","iopub.status.idle":"2024-09-25T04:26:14.655817Z","shell.execute_reply.started":"2024-09-25T04:24:02.504617Z","shell.execute_reply":"2024-09-25T04:26:14.654480Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv')\nsubmission['row_id'] = 'samples'","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:25:31.527822Z","iopub.execute_input":"2024-09-28T17:25:31.528286Z","iopub.status.idle":"2024-09-28T17:25:31.537087Z","shell.execute_reply.started":"2024-09-28T17:25:31.528241Z","shell.execute_reply":"2024-09-28T17:25:31.535793Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Create a dictionary based on all combinations and whether models are available for them or not","metadata":{}},{"cell_type":"code","source":"conditions = ['spinal_canal_stenosis', 'neural_foraminal_narrowing', 'subarticular_stenosis']\nsides = ['left', 'right']\nvertebrae_levels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n# severity_levels = ['normal_mild', 'moderate', 'severe']\nseverity_levels = ['moderate', 'normal_mild', 'severe']\n\ncondn_sides_vrtlvl_combos = product(conditions, sides, vertebrae_levels)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:25:33.772590Z","iopub.execute_input":"2024-09-28T17:25:33.773085Z","iopub.status.idle":"2024-09-28T17:25:33.780396Z","shell.execute_reply.started":"2024-09-28T17:25:33.773040Z","shell.execute_reply":"2024-09-28T17:25:33.778722Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"combinations = {}\n\nfor i in condn_sides_vrtlvl_combos:\n    #print(i)\n    if i[0] == 'spinal_canal_stenosis':\n        if (i[2] == 'l4_l5') or (i[2] == 'l5_s1'):\n            combinations[i[0]+'_'+i[2]] = 'Y'\n        else:\n            combinations[i[0]+'_'+i[2]] = 'N'\n    else:\n        if (i[1] == 'left') and (i[0] == 'neural_foraminal_narrowing'):\n            if i[2] == 'l1_l2':\n                combinations[i[1]+'_'+i[0]+'_'+i[2]] = 'Y'\n            else:\n                combinations[i[1]+'_'+i[0]+'_'+i[2]] = 'N'\n        else:\n            combinations[i[1]+'_'+i[0]+'_'+i[2]] = 'N'\n            \n#print(combinations)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:25:43.883199Z","iopub.execute_input":"2024-09-28T17:25:43.884178Z","iopub.status.idle":"2024-09-28T17:25:43.894982Z","shell.execute_reply.started":"2024-09-28T17:25:43.883926Z","shell.execute_reply":"2024-09-28T17:25:43.893741Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"combinations","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:25:46.485163Z","iopub.execute_input":"2024-09-28T17:25:46.485675Z","iopub.status.idle":"2024-09-28T17:25:46.496788Z","shell.execute_reply.started":"2024-09-28T17:25:46.485628Z","shell.execute_reply":"2024-09-28T17:25:46.495296Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'spinal_canal_stenosis_l1_l2': 'N',\n 'spinal_canal_stenosis_l2_l3': 'N',\n 'spinal_canal_stenosis_l3_l4': 'N',\n 'spinal_canal_stenosis_l4_l5': 'Y',\n 'spinal_canal_stenosis_l5_s1': 'Y',\n 'left_neural_foraminal_narrowing_l1_l2': 'Y',\n 'left_neural_foraminal_narrowing_l2_l3': 'N',\n 'left_neural_foraminal_narrowing_l3_l4': 'N',\n 'left_neural_foraminal_narrowing_l4_l5': 'N',\n 'left_neural_foraminal_narrowing_l5_s1': 'N',\n 'right_neural_foraminal_narrowing_l1_l2': 'N',\n 'right_neural_foraminal_narrowing_l2_l3': 'N',\n 'right_neural_foraminal_narrowing_l3_l4': 'N',\n 'right_neural_foraminal_narrowing_l4_l5': 'N',\n 'right_neural_foraminal_narrowing_l5_s1': 'N',\n 'left_subarticular_stenosis_l1_l2': 'N',\n 'left_subarticular_stenosis_l2_l3': 'N',\n 'left_subarticular_stenosis_l3_l4': 'N',\n 'left_subarticular_stenosis_l4_l5': 'N',\n 'left_subarticular_stenosis_l5_s1': 'N',\n 'right_subarticular_stenosis_l1_l2': 'N',\n 'right_subarticular_stenosis_l2_l3': 'N',\n 'right_subarticular_stenosis_l3_l4': 'N',\n 'right_subarticular_stenosis_l4_l5': 'N',\n 'right_subarticular_stenosis_l5_s1': 'N'}"},"metadata":{}}]},{"cell_type":"code","source":"for st in test_dict.keys():\n    for key, value in combinations.items():\n        if value == 'Y':\n            pass\n        else:\n            rows[st+'_'+key] = np.array([0.333333, 0.333333, 0.333333])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:25:56.083538Z","iopub.execute_input":"2024-09-28T17:25:56.084472Z","iopub.status.idle":"2024-09-28T17:25:56.092691Z","shell.execute_reply.started":"2024-09-28T17:25:56.084417Z","shell.execute_reply":"2024-09-28T17:25:56.091143Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"rows","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:20:40.763429Z","iopub.execute_input":"2024-09-28T17:20:40.763919Z","iopub.status.idle":"2024-09-28T17:20:40.785180Z","shell.execute_reply.started":"2024-09-28T17:20:40.763874Z","shell.execute_reply":"2024-09-28T17:20:40.783790Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'4290709089_left_neural_foraminal_narrowing_l1_l2': array([0.11795083, 0.8639113 , 0.01813781], dtype=float32),\n '1641631752_left_neural_foraminal_narrowing_l1_l2': array([0.11788788, 0.8637801 , 0.01833196], dtype=float32),\n '3220085946_left_neural_foraminal_narrowing_l1_l2': array([0.1176634 , 0.8638491 , 0.01848754], dtype=float32),\n '2361533111_left_neural_foraminal_narrowing_l1_l2': array([0.11848991, 0.8628298 , 0.01868039], dtype=float32),\n '481397395_left_neural_foraminal_narrowing_l1_l2': array([0.11762601, 0.86404085, 0.01833296], dtype=float32),\n '2434132259_left_neural_foraminal_narrowing_l1_l2': array([0.11831606, 0.86297053, 0.01871359], dtype=float32),\n '3581755700_left_neural_foraminal_narrowing_l1_l2': array([0.11850445, 0.8628451 , 0.0186505 ], dtype=float32),\n '987719637_left_neural_foraminal_narrowing_l1_l2': array([0.11819403, 0.86313504, 0.0186708 ], dtype=float32),\n '2030054462_left_neural_foraminal_narrowing_l1_l2': array([0.11772036, 0.86391985, 0.01835985], dtype=float32),\n '4035562923_left_neural_foraminal_narrowing_l1_l2': array([0.1177482 , 0.86387545, 0.01837636], dtype=float32),\n '2508151528_left_neural_foraminal_narrowing_l1_l2': array([0.11832365, 0.8632958 , 0.01838044], dtype=float32),\n '3721755136_left_neural_foraminal_narrowing_l1_l2': array([0.11791442, 0.8636593 , 0.01842621], dtype=float32),\n '3835824946_left_neural_foraminal_narrowing_l1_l2': array([0.11884601, 0.8622949 , 0.01885903], dtype=float32),\n '1614488620_left_neural_foraminal_narrowing_l1_l2': array([0.11789095, 0.8637389 , 0.01837021], dtype=float32),\n '1125605580_left_neural_foraminal_narrowing_l1_l2': array([0.1180368 , 0.8635071 , 0.01845583], dtype=float32),\n '329807127_left_neural_foraminal_narrowing_l1_l2': array([0.11773194, 0.8639866 , 0.01828145], dtype=float32),\n '1960041251_left_neural_foraminal_narrowing_l1_l2': array([0.11785021, 0.8639161 , 0.01823357], dtype=float32),\n '2842534107_left_neural_foraminal_narrowing_l1_l2': array([0.11820011, 0.86326593, 0.01853391], dtype=float32),\n '425970461_left_neural_foraminal_narrowing_l1_l2': array([0.11801318, 0.86350405, 0.01848294], dtype=float32),\n '1449902148_left_neural_foraminal_narrowing_l1_l2': array([0.11748935, 0.86429095, 0.01821961], dtype=float32),\n '4290709089_spinal_canal_stenosis_l4_l5': array([0.11795083, 0.8639113 , 0.01813781], dtype=float32),\n '1641631752_spinal_canal_stenosis_l4_l5': array([0.11788788, 0.8637801 , 0.01833196], dtype=float32),\n '3220085946_spinal_canal_stenosis_l4_l5': array([0.1176634 , 0.8638491 , 0.01848754], dtype=float32),\n '2361533111_spinal_canal_stenosis_l4_l5': array([0.11848991, 0.8628298 , 0.01868039], dtype=float32),\n '481397395_spinal_canal_stenosis_l4_l5': array([0.11762601, 0.86404085, 0.01833296], dtype=float32),\n '2434132259_spinal_canal_stenosis_l4_l5': array([0.11831606, 0.86297053, 0.01871359], dtype=float32),\n '3581755700_spinal_canal_stenosis_l4_l5': array([0.11850445, 0.8628451 , 0.0186505 ], dtype=float32),\n '987719637_spinal_canal_stenosis_l4_l5': array([0.11819403, 0.86313504, 0.0186708 ], dtype=float32),\n '2030054462_spinal_canal_stenosis_l4_l5': array([0.11772036, 0.86391985, 0.01835985], dtype=float32),\n '4035562923_spinal_canal_stenosis_l4_l5': array([0.1177482 , 0.86387545, 0.01837636], dtype=float32),\n '2508151528_spinal_canal_stenosis_l4_l5': array([0.11832365, 0.8632958 , 0.01838044], dtype=float32),\n '3721755136_spinal_canal_stenosis_l4_l5': array([0.11791442, 0.8636593 , 0.01842621], dtype=float32),\n '3835824946_spinal_canal_stenosis_l4_l5': array([0.11884601, 0.8622949 , 0.01885903], dtype=float32),\n '1614488620_spinal_canal_stenosis_l4_l5': array([0.11789095, 0.8637389 , 0.01837021], dtype=float32),\n '1125605580_spinal_canal_stenosis_l4_l5': array([0.1180368 , 0.8635071 , 0.01845583], dtype=float32),\n '329807127_spinal_canal_stenosis_l4_l5': array([0.11773194, 0.8639866 , 0.01828145], dtype=float32),\n '1960041251_spinal_canal_stenosis_l4_l5': array([0.11785021, 0.8639161 , 0.01823357], dtype=float32),\n '2842534107_spinal_canal_stenosis_l4_l5': array([0.11820011, 0.86326593, 0.01853391], dtype=float32),\n '425970461_spinal_canal_stenosis_l4_l5': array([0.11801318, 0.86350405, 0.01848294], dtype=float32),\n '1449902148_spinal_canal_stenosis_l4_l5': array([0.11748935, 0.86429095, 0.01821961], dtype=float32),\n '4290709089_spinal_canal_stenosis_l5_s1': array([0.11795083, 0.8639113 , 0.01813781], dtype=float32),\n '1641631752_spinal_canal_stenosis_l5_s1': array([0.11788788, 0.8637801 , 0.01833196], dtype=float32),\n '3220085946_spinal_canal_stenosis_l5_s1': array([0.1176634 , 0.8638491 , 0.01848754], dtype=float32),\n '2361533111_spinal_canal_stenosis_l5_s1': array([0.11848991, 0.8628298 , 0.01868039], dtype=float32),\n '481397395_spinal_canal_stenosis_l5_s1': array([0.11762601, 0.86404085, 0.01833296], dtype=float32),\n '2434132259_spinal_canal_stenosis_l5_s1': array([0.11831606, 0.86297053, 0.01871359], dtype=float32),\n '3581755700_spinal_canal_stenosis_l5_s1': array([0.11850445, 0.8628451 , 0.0186505 ], dtype=float32),\n '987719637_spinal_canal_stenosis_l5_s1': array([0.11819403, 0.86313504, 0.0186708 ], dtype=float32),\n '2030054462_spinal_canal_stenosis_l5_s1': array([0.11772036, 0.86391985, 0.01835985], dtype=float32),\n '4035562923_spinal_canal_stenosis_l5_s1': array([0.1177482 , 0.86387545, 0.01837636], dtype=float32),\n '2508151528_spinal_canal_stenosis_l5_s1': array([0.11832365, 0.8632958 , 0.01838044], dtype=float32),\n '3721755136_spinal_canal_stenosis_l5_s1': array([0.11791442, 0.8636593 , 0.01842621], dtype=float32),\n '3835824946_spinal_canal_stenosis_l5_s1': array([0.11884601, 0.8622949 , 0.01885903], dtype=float32),\n '1614488620_spinal_canal_stenosis_l5_s1': array([0.11789095, 0.8637389 , 0.01837021], dtype=float32),\n '1125605580_spinal_canal_stenosis_l5_s1': array([0.1180368 , 0.8635071 , 0.01845583], dtype=float32),\n '329807127_spinal_canal_stenosis_l5_s1': array([0.11773194, 0.8639866 , 0.01828145], dtype=float32),\n '1960041251_spinal_canal_stenosis_l5_s1': array([0.11785021, 0.8639161 , 0.01823357], dtype=float32),\n '2842534107_spinal_canal_stenosis_l5_s1': array([0.11820011, 0.86326593, 0.01853391], dtype=float32),\n '425970461_spinal_canal_stenosis_l5_s1': array([0.11801318, 0.86350405, 0.01848294], dtype=float32),\n '1449902148_spinal_canal_stenosis_l5_s1': array([0.11748935, 0.86429095, 0.01821961], dtype=float32)}"},"metadata":{}}]},{"cell_type":"code","source":"# weight_dict = {'normal_mild':1, 'moderate':2, 'severe':4}\n\"\"\"conditions = ['spinal_canal_stenosis', 'neural_foraminal_narrowing', 'subarticular_stenosis']\nsides = ['left', 'right']\nvertebrae_levels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\nseverity_levels = ['normal_mild', 'moderate', 'severe']\n\nfor c in conditions:\n    for v in vertebrae_levels:\n        if c != 'spinal_canal_stenosis':\n            for s in sides:\n                if s+'_'+c != 'right_neural_foraminal_narrowing':\n                    for st in test_dict.keys():\n                        rows[st+'_'+s+'_'+c+'_'+v] = np.array([0.333333, 0.333333, 0.333333])\n                else:\n                    pass\n        else:\n            pass\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-09-21T12:53:05.863368Z","iopub.execute_input":"2024-09-21T12:53:05.863853Z","iopub.status.idle":"2024-09-21T12:53:05.889523Z","shell.execute_reply.started":"2024-09-21T12:53:05.863807Z","shell.execute_reply":"2024-09-21T12:53:05.887969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if Test:\n    for row_id, feature in tqdm(rows.items()):\n        feature_set_reshaped = feature.reshape(1, -1)\n        predictions = np.ascontiguousarray(feature_set_reshaped)\n        df = pd.DataFrame(predictions, columns=severity_levels)\n        df.insert(loc=0, column='row_id', value=row_id)\n        submission = pd.concat([submission,df]).reset_index(drop=True)\n\n    i = submission[(submission.row_id == 'samples')].index\n    submission = submission.drop(i).reset_index(drop=True)\nelse:\n    for row_id, feature in rows.items():\n        feature_set_reshaped = feature.reshape(1, -1)\n        predictions = np.ascontiguousarray(feature_set_reshaped)\n        df = pd.DataFrame(predictions, columns=severity_levels)\n        df.insert(loc=0, column='row_id', value=row_id)\n        submission = pd.concat([submission,df]).reset_index(drop=True)\n\n    i = submission[(submission.row_id == 'samples')].index\n    submission = submission.drop(i).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:25:59.640897Z","iopub.execute_input":"2024-09-28T17:25:59.641322Z","iopub.status.idle":"2024-09-28T17:26:00.531011Z","shell.execute_reply.started":"2024-09-28T17:25:59.641281Z","shell.execute_reply":"2024-09-28T17:26:00.529771Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"100%|██████████| 500/500 [00:00<00:00, 574.15it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T06:43:29.439617Z","iopub.execute_input":"2024-09-28T06:43:29.441237Z","iopub.status.idle":"2024-09-28T06:43:29.452824Z","shell.execute_reply.started":"2024-09-28T06:43:29.441183Z","shell.execute_reply":"2024-09-28T06:43:29.451410Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"if Test:\n    calculate_final_score(solution_data, submission)\n    print(set(solution_data['location'] == submission['location']))","metadata":{"execution":{"iopub.status.busy":"2024-09-28T17:26:15.474091Z","iopub.execute_input":"2024-09-28T17:26:15.474505Z","iopub.status.idle":"2024-09-28T17:26:15.539388Z","shell.execute_reply.started":"2024-09-28T17:26:15.474467Z","shell.execute_reply":"2024-09-28T17:26:15.537971Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"final score during training :  0.9065361555318086\n{True}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}