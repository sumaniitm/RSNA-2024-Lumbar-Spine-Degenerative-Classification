{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":89324,"sourceType":"modelInstanceVersion","modelInstanceId":74932,"modelId":99654}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport polars as pl\n# import duckdb as dd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport cv2\nfrom pydicom import dcmread\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\nimport gc\nimport ctypes\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow_io as tfio\nfrom tensorflow import keras\nfrom tensorflow.python.keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:13:40.598597Z","iopub.execute_input":"2024-08-20T12:13:40.599401Z","iopub.status.idle":"2024-08-20T12:13:55.705828Z","shell.execute_reply.started":"2024-08-20T12:13:40.599368Z","shell.execute_reply":"2024-08-20T12:13:55.704861Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-20 12:13:44.418800: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-20 12:13:44.418923: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-20 12:13:44.592981: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\ntry: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:14:22.029913Z","iopub.execute_input":"2024-08-20T12:14:22.030564Z","iopub.status.idle":"2024-08-20T12:14:23.111092Z","shell.execute_reply.started":"2024-08-20T12:14:22.030532Z","shell.execute_reply":"2024-08-20T12:14:23.110148Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Number of accelerators:  2\n","output_type":"stream"}]},{"cell_type":"code","source":"model = keras.models.\\\nload_model(\"/kaggle/input/keras_base_lnfn_l1_l2/keras/default/1/keras_base_left_neural_foraminal_narrowing_l1_l2.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:14:26.166594Z","iopub.execute_input":"2024-08-20T12:14:26.167572Z","iopub.status.idle":"2024-08-20T12:14:26.304332Z","shell.execute_reply.started":"2024-08-20T12:14:26.167538Z","shell.execute_reply":"2024-08-20T12:14:26.303604Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv')\nsubmission['row_id'] = 'samples'","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:14:29.179101Z","iopub.execute_input":"2024-08-20T12:14:29.179850Z","iopub.status.idle":"2024-08-20T12:14:29.197680Z","shell.execute_reply.started":"2024-08-20T12:14:29.179817Z","shell.execute_reply":"2024-08-20T12:14:29.196393Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"Test = True\nconfig = {}\n\nif Test:\n    config['root_file_path'] = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\n    config['start'] = 100\n    config['end'] = 350\n    studies = os.listdir(config['root_file_path'])[config['start']:config['end']]\n    test_dict = {}\n    image_files = []\n\n    for study in studies:\n        for dirname, _, filenames in os.walk(config['root_file_path']+'/'+study):\n            for filename in filenames:\n                test_dict[os.path.join(dirname, filename).split('/')[-3]] = image_files\n                image_files.append(os.path.join(dirname, filename))\nelse:\n    config['root_file_path'] = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/'\n    test_dict = {}\n    image_files = []\n\n    for dirname, _, filenames in os.walk(config['root_file_path']):\n        for filename in filenames:\n            test_dict[os.path.join(dirname, filename).split('/')[-3]] = image_files\n            image_files.append(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:14:33.771119Z","iopub.execute_input":"2024-08-20T12:14:33.771442Z","iopub.status.idle":"2024-08-20T12:14:39.330235Z","shell.execute_reply.started":"2024-08-20T12:14:33.771419Z","shell.execute_reply":"2024-08-20T12:14:39.329460Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"image_files_list = []\n\nfor key, val in test_dict.items():\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_files_list = list(test_dict.keys())\n\ndataset_to_predict_for = tf.data.Dataset.from_tensor_slices(image_files_list)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:14:49.057132Z","iopub.execute_input":"2024-08-20T12:14:49.057779Z","iopub.status.idle":"2024-08-20T12:14:49.067739Z","shell.execute_reply.started":"2024-08-20T12:14:49.057749Z","shell.execute_reply":"2024-08-20T12:14:49.066800Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"type(dataset_to_predict_for)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:14:51.934796Z","iopub.execute_input":"2024-08-20T12:14:51.935396Z","iopub.status.idle":"2024-08-20T12:14:51.942053Z","shell.execute_reply.started":"2024-08-20T12:14:51.935365Z","shell.execute_reply":"2024-08-20T12:14:51.941044Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"},"metadata":{}}]},{"cell_type":"code","source":"def read_and_parse_dicom_files(full_file_path):\n    tf.config.run_functions_eagerly(True)\n    raw_image = tf.io.read_file(full_file_path)\n    sp = tf.strings.split(tf.gather(tf.strings.split(full_file_path, 'images/'), 1), '/')\n    N = tf.size(sp)\n    LEN = tf.strings.length(tf.gather(sp, 0))+tf.strings.length(tf.gather(sp, 2))\n    \n    # Add missing file metadata to avoid warnnigs flooding\n    if   LEN==12: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x92\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==13: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x92\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==14: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x94\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==15: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x94\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==16: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x96\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==17: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x96\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==18: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x98\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    \n    #image_bytes = tf.io.read_file(full_file_path)\n    #image = tfio.image.decode_dicom_image(image_bytes, scale='auto', dtype=tf.float32)\n    image = tfio.image.decode_dicom_image(raw_image, scale='auto', dtype=tf.float32)\n    #m, M=tf.math.reduce_min(image), tf.math.reduce_max(image)\n    #image = (tf.image.grayscale_to_rgb(image)-m)/(M-m)\n    image = tf.image.resize(image, (128,128))\n    return tf.squeeze(image)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:14:54.217938Z","iopub.execute_input":"2024-08-20T12:14:54.218836Z","iopub.status.idle":"2024-08-20T12:14:54.228974Z","shell.execute_reply.started":"2024-08-20T12:14:54.218802Z","shell.execute_reply":"2024-08-20T12:14:54.228188Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset_to_predict_for = dataset_to_predict_for.map(read_and_parse_dicom_files, num_parallel_calls=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:14:57.835711Z","iopub.execute_input":"2024-08-20T12:14:57.836064Z","iopub.status.idle":"2024-08-20T12:14:58.936329Z","shell.execute_reply.started":"2024-08-20T12:14:57.836036Z","shell.execute_reply":"2024-08-20T12:14:58.935329Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset_to_predict_for = dataset_to_predict_for.batch(batch_size=32)\ndataset_to_predict_for = dataset_to_predict_for.prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:15:04.640909Z","iopub.execute_input":"2024-08-20T12:15:04.641619Z","iopub.status.idle":"2024-08-20T12:15:04.650563Z","shell.execute_reply.started":"2024-08-20T12:15:04.641587Z","shell.execute_reply":"2024-08-20T12:15:04.649628Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# dataset_to_predict_for.take(1)\nelem = next(iter(dataset_to_predict_for))\nelem","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:15:06.323181Z","iopub.execute_input":"2024-08-20T12:15:06.323998Z","iopub.status.idle":"2024-08-20T12:15:08.859099Z","shell.execute_reply.started":"2024-08-20T12:15:06.323969Z","shell.execute_reply":"2024-08-20T12:15:08.857941Z"},"trusted":true},"execution_count":11,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# dataset_to_predict_for.take(1)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m elem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset_to_predict_for\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m elem\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3029\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3029\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3031\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices = 1 is not in [0, 1)\n\t [[{{node GatherV2}}]] [Op:IteratorGetNext] name: "],"ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices = 1 is not in [0, 1)\n\t [[{{node GatherV2}}]] [Op:IteratorGetNext] name: ","output_type":"error"}]},{"cell_type":"code","source":"with strategy.scope():\n    \n    def get_feature_array(img_file_list):\n        dicom_ds = dcmread(img_file_list)\n        img_array = dicom_ds.pixel_array\n        return np.resize(np.mean(img_array.T, axis=0),(128,))\n\n    vfunc = np.vectorize(get_feature_array, otypes=[object])\n    \n    def get_predictions(key, model_to_use):\n        if Test:\n            pbar.update(1)\n        final_feature_list = vfunc(test_dict[key]).tolist()\n        final = np.array(final_feature_list)\n        return model_to_use.predict(final)\n\n    vfunc2 = np.vectorize(get_predictions, otypes=[object])\n    \n    if Test:\n        global pbar \n        pbar = 0\n\n        with tqdm(total=len(test_dict.keys())) as pbar:\n            y_proba = vfunc2(list(test_dict.keys()), model)\n    else:\n        y_proba = vfunc2(list(test_dict.keys()), model)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T05:12:16.004040Z","iopub.execute_input":"2024-08-19T05:12:16.004611Z","iopub.status.idle":"2024-08-19T05:12:19.673516Z","shell.execute_reply.started":"2024-08-19T05:12:16.004581Z","shell.execute_reply":"2024-08-19T05:12:19.672620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = {}\n# weight_dict = {'normal_mild':1, 'moderate':2, 'severe':4}\nconditions = ['spinal_canal_stenosis', 'neural_foraminal_narrowing', 'subarticular_stenosis']\nsides = ['left', 'right']\nvertebrae_levels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\nseverity_levels = ['normal_mild', 'moderate', 'severe']\n\nfor c in conditions:\n    for v in vertebrae_levels:\n        if c != 'spinal_canal_stenosis':\n            for s in sides:\n                for st in test_dict.keys():\n                    if s+'_'+c+'_'+v == 'left_neural_foraminal_narrowing_l1_l2':\n                        #print(\"going for model \", st+'_'+s+'_'+c+'_'+v)\n                        pass\n                    else:\n                        #print(st+'_'+s+'_'+c+'_'+v)\n                        rows[st+'_'+s+'_'+c+'_'+v] = np.array([0.333333, 0.333333, 0.333333])\n        else:\n            for st in test_dict.keys():\n                #print(st+'_'+c+'_'+v)\n                rows[st+'_'+c+'_'+v] = np.array([0.333333, 0.333333, 0.333333])","metadata":{"execution":{"iopub.status.busy":"2024-08-19T05:12:25.900639Z","iopub.execute_input":"2024-08-19T05:12:25.901267Z","iopub.status.idle":"2024-08-19T05:12:25.908990Z","shell.execute_reply.started":"2024-08-19T05:12:25.901238Z","shell.execute_reply":"2024-08-19T05:12:25.908059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dict_key_list = list(test_dict.keys())\n\nfor st in range(len(test_dict_key_list)):\n    # print(test_dict_key_list[st])\n    rows[test_dict_key_list[st]+'_left_neural_foraminal_narrowing_l1_l2'] = np.mean(y_proba[st], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T05:12:30.273339Z","iopub.execute_input":"2024-08-19T05:12:30.274198Z","iopub.status.idle":"2024-08-19T05:12:30.279096Z","shell.execute_reply.started":"2024-08-19T05:12:30.274167Z","shell.execute_reply":"2024-08-19T05:12:30.278095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for row_id, feature in tqdm(rows.items()):\n    feature_set_reshaped = feature.reshape(1, -1)\n    predictions = np.ascontiguousarray(feature_set_reshaped)\n    df = pd.DataFrame(predictions, columns=severity_levels)\n    df.insert(loc=0, column='row_id', value=row_id)\n    submission = pd.concat([submission,df]).reset_index(drop=True)\n    \ni = submission[(submission.row_id == 'samples')].index\nsubmission = submission.drop(i).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T05:12:32.335543Z","iopub.execute_input":"2024-08-19T05:12:32.335912Z","iopub.status.idle":"2024-08-19T05:12:32.382155Z","shell.execute_reply.started":"2024-08-19T05:12:32.335883Z","shell.execute_reply":"2024-08-19T05:12:32.381037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T05:13:00.044311Z","iopub.execute_input":"2024-08-19T05:13:00.045145Z","iopub.status.idle":"2024-08-19T05:13:00.052890Z","shell.execute_reply.started":"2024-08-19T05:13:00.045113Z","shell.execute_reply":"2024-08-19T05:13:00.051955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}