{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport polars as pl\n# import duckdb as dd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport cv2\nfrom pydicom import dcmread\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\nimport gc\nimport ctypes\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow_io as tfio\nfrom tensorflow import keras\nfrom tensorflow.python.keras import backend as K\nfrom joblib import Parallel, delayed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-22T13:21:05.731387Z","iopub.execute_input":"2024-08-22T13:21:05.731897Z","iopub.status.idle":"2024-08-22T13:21:24.848229Z","shell.execute_reply.started":"2024-08-22T13:21:05.731846Z","shell.execute_reply":"2024-08-22T13:21:24.846537Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"Test = False\nconfig = {}\n\nif Test:\n    config['root_file_path'] = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\n    config['start'] = 400\n    config['end'] = 500\n    studies = os.listdir(config['root_file_path'])[config['start']:config['end']]\n    test_dict = {}\n\n    for study in studies:\n        image_files = []\n        for dirname, _, filenames in os.walk(config['root_file_path']+'/'+study):\n            for filename in filenames:\n                test_dict[os.path.join(dirname, filename).split('/')[-3]] = image_files\n                image_files.append(os.path.join(dirname, filename))\nelse:\n    config['root_file_path'] = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/'\n    test_dict = {}\n    image_files = []\n\n    for dirname, _, filenames in os.walk(config['root_file_path']):\n        for filename in filenames:\n            test_dict[os.path.join(dirname, filename).split('/')[-3]] = image_files\n            image_files.append(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-08-22T13:21:33.468343Z","iopub.execute_input":"2024-08-22T13:21:33.469548Z","iopub.status.idle":"2024-08-22T13:21:33.506003Z","shell.execute_reply.started":"2024-08-22T13:21:33.469473Z","shell.execute_reply":"2024-08-22T13:21:33.504287Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from multiprocessing import cpu_count\nn_cores = cpu_count()\nprint(f'Number of Logical CPU cores: {n_cores}')","metadata":{"execution":{"iopub.status.busy":"2024-08-22T13:21:36.277198Z","iopub.execute_input":"2024-08-22T13:21:36.277732Z","iopub.status.idle":"2024-08-22T13:21:36.285452Z","shell.execute_reply.started":"2024-08-22T13:21:36.277660Z","shell.execute_reply":"2024-08-22T13:21:36.284105Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Number of Logical CPU cores: 4\n","output_type":"stream"}]},{"cell_type":"code","source":"model = keras.models.\\\nload_model(\"/kaggle/input/keras_base_lnfn_l1_l2/keras/default/1/keras_base_left_neural_foraminal_narrowing_l1_l2.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-08-22T13:21:38.352114Z","iopub.execute_input":"2024-08-22T13:21:38.352570Z","iopub.status.idle":"2024-08-22T13:21:38.541417Z","shell.execute_reply.started":"2024-08-22T13:21:38.352529Z","shell.execute_reply":"2024-08-22T13:21:38.539080Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv')\nsubmission['row_id'] = 'samples'","metadata":{"execution":{"iopub.status.busy":"2024-08-22T13:21:43.054068Z","iopub.execute_input":"2024-08-22T13:21:43.054645Z","iopub.status.idle":"2024-08-22T13:21:43.078897Z","shell.execute_reply.started":"2024-08-22T13:21:43.054595Z","shell.execute_reply":"2024-08-22T13:21:43.077162Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_feature_array(img_file_list):\n    #pbar.update(1)\n    dicom_ds = dcmread(img_file_list)\n    img_array = dicom_ds.pixel_array\n    return np.resize(np.mean(img_array.T, axis=0),(128,))\n\nvfunc = np.vectorize(get_feature_array, otypes=[object])\n\ndef get_predictions(key, model_to_use):\n    final_feature_list = vfunc(test_dict[key]).tolist()\n    final = np.array(final_feature_list)\n    return model_to_use.predict(final)\n\n\"\"\"parallel = Parallel(n_jobs=4, return_as=\"generator\")\noutput_generator = parallel(delayed(vfunc)(test_dict[st]) for st in tqdm(test_dict.keys()))\nfinal_feature_list = list(output_generator)\"\"\"\n\ny_proba = (Parallel(n_jobs=4)(delayed(get_predictions)(st, model) for st in tqdm(test_dict.keys())))","metadata":{"execution":{"iopub.status.busy":"2024-08-22T13:21:46.386601Z","iopub.execute_input":"2024-08-22T13:21:46.387116Z","iopub.status.idle":"2024-08-22T13:21:55.503043Z","shell.execute_reply.started":"2024-08-22T13:21:46.387069Z","shell.execute_reply":"2024-08-22T13:21:55.501590Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 35.59it/s]\n/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step \n","output_type":"stream"}]},{"cell_type":"code","source":"rows = {}\n\nfor i in range(len(y_proba)):\n    rows[list(test_dict.keys())[i]+'_left_neural_foraminal_narrowing_l1_l2'] = np.mean(y_proba[i], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T13:22:09.829359Z","iopub.execute_input":"2024-08-22T13:22:09.829848Z","iopub.status.idle":"2024-08-22T13:22:09.837838Z","shell.execute_reply.started":"2024-08-22T13:22:09.829802Z","shell.execute_reply":"2024-08-22T13:22:09.836262Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#rows = {}\n# weight_dict = {'normal_mild':1, 'moderate':2, 'severe':4}\nconditions = ['spinal_canal_stenosis', 'neural_foraminal_narrowing', 'subarticular_stenosis']\nsides = ['left', 'right']\nvertebrae_levels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\nseverity_levels = ['normal_mild', 'moderate', 'severe']\n\nfor c in conditions:\n    for v in vertebrae_levels:\n        if c != 'spinal_canal_stenosis':\n            for s in sides:\n                for st in test_dict.keys():\n                    if s+'_'+c+'_'+v == 'left_neural_foraminal_narrowing_l1_l2':\n                        #print(\"going for model \", st+'_'+s+'_'+c+'_'+v)\n                        pass\n                    else:\n                        #print(st+'_'+s+'_'+c+'_'+v)\n                        rows[st+'_'+s+'_'+c+'_'+v] = np.array([0.333333, 0.333333, 0.333333])\n        else:\n            for st in test_dict.keys():\n                #print(st+'_'+c+'_'+v)\n                rows[st+'_'+c+'_'+v] = np.array([0.333333, 0.333333, 0.333333])","metadata":{"execution":{"iopub.status.busy":"2024-08-22T13:22:25.443944Z","iopub.execute_input":"2024-08-22T13:22:25.444595Z","iopub.status.idle":"2024-08-22T13:22:25.459544Z","shell.execute_reply.started":"2024-08-22T13:22:25.444534Z","shell.execute_reply":"2024-08-22T13:22:25.457602Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for row_id, feature in tqdm(rows.items()):\n    feature_set_reshaped = feature.reshape(1, -1)\n    predictions = np.ascontiguousarray(feature_set_reshaped)\n    df = pd.DataFrame(predictions, columns=severity_levels)\n    df.insert(loc=0, column='row_id', value=row_id)\n    submission = pd.concat([submission,df]).reset_index(drop=True)\n    \ni = submission[(submission.row_id == 'samples')].index\nsubmission = submission.drop(i).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T13:22:27.725004Z","iopub.execute_input":"2024-08-22T13:22:27.727146Z","iopub.status.idle":"2024-08-22T13:22:27.785354Z","shell.execute_reply.started":"2024-08-22T13:22:27.727078Z","shell.execute_reply":"2024-08-22T13:22:27.783410Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"100%|██████████| 25/25 [00:00<00:00, 749.43it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T13:22:31.942659Z","iopub.execute_input":"2024-08-22T13:22:31.943348Z","iopub.status.idle":"2024-08-22T13:22:31.958289Z","shell.execute_reply.started":"2024-08-22T13:22:31.943285Z","shell.execute_reply":"2024-08-22T13:22:31.956491Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}