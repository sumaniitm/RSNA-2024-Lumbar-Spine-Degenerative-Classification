{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":8236972,"sourceType":"datasetVersion","datasetId":4885707},{"sourceId":9155320,"sourceType":"datasetVersion","datasetId":5530686}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import required libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport polars as pl\n#import duckdb as dd\n#from tqdm import tqdm\nimport matplotlib.pyplot as plt\n#import cv2\n#from pydicom import dcmread\nimport warnings\n#from sklearn.preprocessing import LabelEncoder\nimport pickle\n#import gc\nimport ctypes\nimport tensorflow as tf\n#tf.compat.v1.disable_eager_execution()\n#tf.keras.backend.clear_session()\n\n\"\"\"for gpu in tf.config.experimental.list_physical_devices(\"GPU\"):\n    tf.config.experimental.set_memory_growth(gpu, True)\"\"\"\n    \nimport tensorflow_io as tfio\nfrom tensorflow import keras\n\n#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-23T11:54:29.334328Z","iopub.execute_input":"2024-08-23T11:54:29.334712Z","iopub.status.idle":"2024-08-23T11:54:32.830698Z","shell.execute_reply.started":"2024-08-23T11:54:29.334674Z","shell.execute_reply":"2024-08-23T11:54:32.829922Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"try: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:54:42.741407Z","iopub.execute_input":"2024-08-23T11:54:42.742351Z","iopub.status.idle":"2024-08-23T11:54:43.568838Z","shell.execute_reply.started":"2024-08-23T11:54:42.742308Z","shell.execute_reply":"2024-08-23T11:54:43.567866Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Number of accelerators:  2\n","output_type":"stream"}]},{"cell_type":"code","source":"# strategy = tf.distribute.MirroredStrategy()\nprint('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))\n\nBATCH_SIZE_PER_REPLICA = 48\n\n#We obtain the BATCH_SIZE dividing by the number of devices. \nBATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:54:46.941482Z","iopub.execute_input":"2024-08-23T11:54:46.941882Z","iopub.status.idle":"2024-08-23T11:54:46.947354Z","shell.execute_reply.started":"2024-08-23T11:54:46.941831Z","shell.execute_reply":"2024-08-23T11:54:46.946376Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"DEVICES AVAILABLE: 2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Feature extraction from image files\n## Only if not using tensorflow\n### kept here as backward compatibility with earlier work","metadata":{}},{"cell_type":"code","source":"metadata_root_path = '/kaggle/input/spinal-canal-stenosis-metadata'\n\nfor file in os.listdir(metadata_root_path):\n    labels = []\n    features = []\n    data = {}\n    metadata_file_path = os.path.join(metadata_root_path, file)\n    print(metadata_file_path)\n    metadata_df = pl.read_csv(metadata_file_path, low_memory=True)\n    for j in tqdm(range(metadata_df.shape[0])):\n        dcm_image_path = metadata_df.item(j,0)\n        dicom_ds = dcmread(dcm_image_path)\n        img_array = dicom_ds.pixel_array\n        features.append(np.mean(img_array.T, axis=0))\n        # features.append(dcmread(dcm_image_path).pixel_array)\n        labels.append(metadata_df.item(j,2))\n\n    print(\"feature list length --> \", len(features))\n    print(\"label list length --> \", len(labels))\n\n    #extracted_training_features = np.array([np.resize(img,(128,128)) for img in features])\n    #training_labels = np.array(labels)\n\n    #del labels\n    #del features\n    #gc.collect()\n\n    extracted_training_features_file_name = \"{0}_training_features\".format(file.replace('_feature_metadata.csv',''))\n    labels_file_name = \"{0}_labels\".format(file.replace('.csv',''))\n\n    with open(extracted_training_features_file_name, \"wb\") as file:\n        pickle.dump(features, file)\n    with open(labels_file_name, \"wb\") as file:\n        pickle.dump(labels, file)\n\n    del labels\n    del features\n    gc.collect()\n    libc = ctypes.CDLL(\"libc.so.6\") # clearing cache \n    libc.malloc_trim(0)\n\n    #data[\"image_array\"] = features\n    #data[\"encoded_severity\"] = labels\n    #extracted_training_data = pd.DataFrame(data)\n    #extracted_training_data.to_csv(\"{0}.csv.gz\".format(file.replace('.csv','')), index=False, compression='gzip')\n\n    print('finished dumping features & labels for {0}'.format(file))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Review pipeline with one sample image","metadata":{}},{"cell_type":"code","source":"image_bytes \\\n= tf.io.read_file('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/100206310/1012284084/1.dcm')\n\nimage = tfio.image.decode_dicom_image(image_bytes, scale='auto', dtype=tf.float32)\n\nm, M=tf.math.reduce_min(image), tf.math.reduce_max(image)\nimage = (tf.image.grayscale_to_rgb(image)-m)/(M-m)\nimage = tf.image.resize(image, (128,128))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing functions","metadata":{}},{"cell_type":"code","source":"def read_and_parse_dicom_files(full_file_path):\n    tf.config.run_functions_eagerly(True)\n    raw_image = tf.io.read_file(full_file_path)\n    sp = tf.strings.split(tf.gather(tf.strings.split(full_file_path, 'images/'), 1), '/')\n    N = tf.size(sp)\n    LEN = tf.strings.length(tf.gather(sp, 0))+tf.strings.length(tf.gather(sp, 2))\n    \n    # Add missing file metadata to avoid warnnigs flooding\n    if   LEN==12: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x92\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==13: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x92\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==14: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x94\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==15: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x94\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==16: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x96\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==17: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x96\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    elif LEN==18: raw_image = tf.strings.regex_replace(raw_image, pattern=b'DICM\\x02\\x00\\x01\\x00', rewrite=b'DICM\\x02\\x00\\x00\\x00UL\\x04\\x00\\x98\\x00\\x00\\x00\\x02\\x00\\x01\\x00')\n    \n    #image_bytes = tf.io.read_file(full_file_path)\n    #image = tfio.image.decode_dicom_image(image_bytes, scale='auto', dtype=tf.float32)\n    image = tfio.image.decode_dicom_image(raw_image, scale='auto', dtype=tf.float32)\n    m, M=tf.math.reduce_min(image), tf.math.reduce_max(image)\n    image = (tf.image.grayscale_to_rgb(image)-m)/(M-m)\n    image = tf.image.resize(image, (128,128))\n    return tf.squeeze(image)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:54:52.165935Z","iopub.execute_input":"2024-08-23T11:54:52.166320Z","iopub.status.idle":"2024-08-23T11:54:52.177483Z","shell.execute_reply.started":"2024-08-23T11:54:52.166283Z","shell.execute_reply":"2024-08-23T11:54:52.176513Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def load_dataset(image_path, labels):\n    image = read_and_parse_dicom_files(image_path)\n    return {\"images\": tf.cast(image, tf.float32), \"labels\": tf.cast(labels, tf.float32)}\n\ndef dict_to_tuple(inputs):\n    return inputs[\"images\"], inputs[\"labels\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:54:54.865015Z","iopub.execute_input":"2024-08-23T11:54:54.865403Z","iopub.status.idle":"2024-08-23T11:54:54.870996Z","shell.execute_reply.started":"2024-08-23T11:54:54.865366Z","shell.execute_reply":"2024-08-23T11:54:54.869937Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Train, Test, Validation & holdout splits\n## holdout set to be used for CV","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nmetadata_file_path = '/kaggle/input/spinal-canal-stenosis-metadata/spinal_canal_stenosis_l1_l2_feature_metadata.csv'\nmetadata_df = pl.read_csv(metadata_file_path, low_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:54:58.944716Z","iopub.execute_input":"2024-08-23T11:54:58.945507Z","iopub.status.idle":"2024-08-23T11:54:59.400724Z","shell.execute_reply.started":"2024-08-23T11:54:58.945465Z","shell.execute_reply":"2024-08-23T11:54:59.399712Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for_train, holdout = train_test_split(metadata_df, test_size=0.4, random_state=42)\n\nx_train, x_test_val = train_test_split(for_train, test_size=0.3, random_state=42)\nx_test, x_valid = train_test_split(x_test_val, test_size=0.2, random_state=42)\n\nprint(\"Training data shape : {0}\".format(x_train.shape))\nprint(\"Test data shape : {0}\".format(x_test.shape))\nprint(\"Validation data shape : {0}\".format(x_valid.shape))\nprint(\"Holdout data shape : {0}\".format(holdout.shape))","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:55:01.021351Z","iopub.execute_input":"2024-08-23T11:55:01.022018Z","iopub.status.idle":"2024-08-23T11:55:01.066951Z","shell.execute_reply.started":"2024-08-23T11:55:01.021974Z","shell.execute_reply":"2024-08-23T11:55:01.065990Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Training data shape : (61794, 3)\nTest data shape : (21187, 3)\nValidation data shape : (5297, 3)\nHoldout data shape : (58853, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"holdout_image_filenames = pl.Series(holdout.select(pl.col('full_img_path'))).to_list()\nholdout_image_labels = pl.Series(holdout.select(pl.col('encoded_severity'))).to_list()\n\ntrain_image_filenames = pl.Series(x_train.select(pl.col('full_img_path'))).to_list()\ntrain_image_labels = pl.Series(x_train.select(pl.col('encoded_severity'))).to_list()\n\ntest_image_filenames = pl.Series(x_test.select(pl.col('full_img_path'))).to_list()\ntest_image_labels = pl.Series(x_test.select(pl.col('encoded_severity'))).to_list()\n\nvalid_image_filenames = pl.Series(x_valid.select(pl.col('full_img_path'))).to_list()\nvalid_image_labels = pl.Series(x_valid.select(pl.col('encoded_severity'))).to_list()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:55:03.521913Z","iopub.execute_input":"2024-08-23T11:55:03.522590Z","iopub.status.idle":"2024-08-23T11:55:03.576794Z","shell.execute_reply.started":"2024-08-23T11:55:03.522549Z","shell.execute_reply":"2024-08-23T11:55:03.575927Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((train_image_filenames, train_image_labels))\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_image_filenames, test_image_labels))\n\nvalid_dataset = tf.data.Dataset.from_tensor_slices((valid_image_filenames, valid_image_labels))\n\nholdout_dataset = tf.data.Dataset.from_tensor_slices((holdout_image_filenames, holdout_image_labels))","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:55:05.940428Z","iopub.execute_input":"2024-08-23T11:55:05.941221Z","iopub.status.idle":"2024-08-23T11:55:06.891145Z","shell.execute_reply.started":"2024-08-23T11:55:05.941178Z","shell.execute_reply":"2024-08-23T11:55:06.890144Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_ds = train_dataset.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\ntrain_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\ntrain_ds = train_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True)\ntrain_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n\ntest_ds = test_dataset.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\ntest_ds = test_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\ntest_ds = test_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True)\ntest_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n\nvalid_ds = valid_dataset.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\nvalid_ds = valid_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\nvalid_ds = valid_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True)\nvalid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)\n\nholdout_ds = holdout_dataset.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\nholdout_ds = holdout_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\nholdout_ds = holdout_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True)\nholdout_ds = holdout_ds.prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:55:09.061211Z","iopub.execute_input":"2024-08-23T11:55:09.061929Z","iopub.status.idle":"2024-08-23T11:55:10.660779Z","shell.execute_reply.started":"2024-08-23T11:55:09.061888Z","shell.execute_reply":"2024-08-23T11:55:10.659799Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"elem = next(iter(train_ds))\nelem\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras import layers\n\nwith strategy.scope():\n    \n    rsna_input = layers.Input(shape=(128,128,3), name=\"rsna_input\")\n    \n    conv_base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=rsna_input)\n    conv_base.trainable = False\n    \n    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(conv_base.output)\n    x = layers.BatchNormalization()(x)\n    \n    hidden_layer1 = layers.Dense(200, activation=\"relu\", kernel_initializer=keras.initializers.LecunNormal(seed=None))(x)\n    hidden_layer2 = layers.Dense(100, activation=\"selu\")(hidden_layer1)\n    hidden_layer3 = layers.Dense(50, activation=\"selu\")(hidden_layer2)\n    rsna_output = layers.Dense(3, activation=\"softmax\")(hidden_layer3)\n    #model = tf.keras.models.Model(inputs=rsna_input, outputs=rsna_output)\n    model = tf.keras.Model(rsna_input, rsna_output)\n    \n    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"keras_effnet_spinal_canal_stenosis_l1_l2.keras\")\n    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n\n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adamax\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:55:16.055383Z","iopub.execute_input":"2024-08-23T11:55:16.055788Z","iopub.status.idle":"2024-08-23T11:55:18.685978Z","shell.execute_reply.started":"2024-08-23T11:55:16.055749Z","shell.execute_reply":"2024-08-23T11:55:18.684932Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"config = model.get_config()\nprint(config[\"layers\"][0][\"config\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_ds, epochs=5, validation_data=valid_ds, callbacks=[checkpoint_cb, early_stopping_cb])","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:55:26.648551Z","iopub.execute_input":"2024-08-23T11:55:26.649376Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m 25/643\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:23\u001b[0m 1s/step - accuracy: 0.8390 - loss: 0.4682","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot(figsize=(10,6))\nplt.grid(True)\nplt.gca().set_ylim(0.60,1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cropped_image = tf.image.resize_with_crop_or_pad(image, 100, 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,1, figsize=(5,5))\naxes.imshow(np.squeeze(cropped_image.numpy()), cmap='gray')\naxes.set_title('image')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}