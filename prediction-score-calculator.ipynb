{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport polars as pl\n# import duckdb as dd\nfrom tqdm import tqdm\n\"\"\"import matplotlib.pyplot as plt\nimport cv2\nfrom pydicom import dcmread\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\nimport gc\nimport ctypes\"\"\"\n# from sklearn.model_selection import train_test_split\nimport tensorflow as tf\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\nimport tensorflow_io as tfio\nfrom tensorflow import keras\nfrom tensorflow.python.keras import backend as K\nfrom joblib import Parallel, delayed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {}\nconfig['root_file_path'] = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\nconfig['start'] = 10\nconfig['end'] = 110","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encoder(label):\n    if label == 'Normal/Mild':\n        return 2\n    elif label == 'Severe':\n        return 3\n    else:\n        return 1\n    \ndef attach_weights(label):\n    if label == 'Normal/Mild':\n        return 1\n    elif label == 'Severe':\n        return 4\n    else:\n        return 2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_solution_df(run_config):\n    \n    train_studies_metadata_file_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv'\n    train_studies_metadata_df = pl.read_csv(train_studies_metadata_file_path, low_memory=True)\n    print(\"before dropping nulls :\", train_studies_metadata_df.shape)\n    train_studies_metadata_df = train_studies_metadata_df.drop_nulls()\n    print(\"after dropping nulls :\", train_studies_metadata_df.shape)\n\n    studies_full = train_studies_metadata_df.select(pl.col('study_id')).unique().to_series().to_list()\n    print(\"total number of studies : \", len(studies_full))\n    \n    studies = studies_full[run_config['start']:run_config['end']]\n    print(len(studies))\n\n    test_dict = {}\n    for study in studies:\n        image_files = []\n        for dirname, _, filenames in os.walk(config['root_file_path']+'/'+str(study)):\n            for filename in filenames:\n                test_dict[os.path.join(dirname, filename).split('/')[-3]] = image_files\n                image_files.append(os.path.join(dirname, filename))\n\n    print(\"total number of test_dict items : \",len(test_dict))\n    \n    train_studies_metadata_df_up = train_studies_metadata_df.unpivot(index=\"study_id\")\n    train_studies_metadata_df_up.columns = ['study_id', 'condition', 'severity']\n\n    train_studies_metadata_df_up = train_studies_metadata_df_up.with_columns([\n        pl.col(\"severity\").map_elements(label_encoder, return_dtype=pl.Int32).alias(\"encoded_severity\"),\n        pl.col(\"severity\").map_elements(attach_weights, return_dtype=pl.Int32).alias(\"sample_weight\"),\n        (pl.col(\"study_id\").cast(pl.String)+'_'+pl.col(\"condition\")).alias(\"row_id\")\n    ])\n\n    print(\"train_studies_metadata_df_up shape : \",train_studies_metadata_df_up.shape)\n    \n    temp = train_studies_metadata_df_up.select([pl.col('study_id'), pl.col('row_id'), pl.col('encoded_severity'), pl.col('severity'), pl.col('sample_weight')])\n    train_studies_metadata_df_final = temp.pivot(\"severity\", index=[\"study_id\",\"row_id\"], values=\"encoded_severity\")\n    train_studies_metadata_df_final.columns = ['study_id', 'row_id', 'normal_mild', 'moderate', 'severe']\n    \n    train_studies_metadata_df_final_2 = train_studies_metadata_df_final.join(temp, on=[\"study_id\",\"row_id\"], how=\"inner\")\n    train_studies_metadata_df_final_2 = train_studies_metadata_df_final_2.drop(['encoded_severity', 'severity'])\n    train_studies_metadata_df_final_2 = train_studies_metadata_df_final_2.with_columns([\n        pl.when(pl.col('normal_mild').is_not_null()).then(1).otherwise(0).alias('true_normal_mild'),\n        pl.when(pl.col('moderate').is_not_null()).then(1).otherwise(0).alias('true_moderate'),\n        pl.when(pl.col('severe').is_not_null()).then(1).otherwise(0).alias('true_severe'),\n    ])\n    \n    train_studies_metadata_df_final_2 = train_studies_metadata_df_final_2.drop(['normal_mild', 'moderate', 'severe'])\n    train_studies_metadata_df_final_2.columns = ['study_id', 'row_id', 'sample_weight', 'normal_mild', 'moderate', 'severe']\n    \n    solutions = train_studies_metadata_df_final_2.filter(pl.col('study_id').is_in(studies))\n    solutions = solutions.drop(['study_id'])\n    print(\"shape of solutions dataframe : \", solutions.shape)\n    \n    return solutions.to_pandas()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_condition(full_location: str) -> str:\n    # Given an input like spinal_canal_stenosis_l1_l2 extracts 'spinal'\n    for injury_condition in ['spinal', 'foraminal', 'subarticular']:\n        if injury_condition in full_location:\n            return injury_condition\n    raise ValueError(f'condition not found in {full_location}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_final_score(solution, submission):\n    \n    target_levels = ['normal_mild', 'moderate', 'severe']\n\n    if not pd.api.types.is_numeric_dtype(submission[target_levels].values):\n            raise ParticipantVisibleError('All submission values must be numeric')\n\n    if not np.isfinite(submission[target_levels].values).all():\n        raise ParticipantVisibleError('All submission values must be finite')\n\n    if solutions_pd[target_levels].min().min() < 0:\n        raise ParticipantVisibleError('All labels must be at least zero')\n    if submission[target_levels].min().min() < 0:\n        raise ParticipantVisibleError('All predictions must be at least zero')\n        \n    solutions['study_id'] = solutions['row_id'].apply(lambda x: x.split('_')[0])\n    solutions['location'] = solutions['row_id'].apply(lambda x: '_'.join(x.split('_')[1:]))\n    solutions['condition'] = solutions['row_id'].apply(get_condition)\n    \n    row_id_column_name = 'row_id'\n\n    del solutions[row_id_column_name]\n    del submission[row_id_column_name]\n    assert sorted(submission.columns) == sorted(target_levels)\n\n    submission['study_id'] = solutions['study_id']\n    submission['location'] = solutions['location']\n    submission['condition'] = solutions['condition']\n    \n    condition_losses = []\n    condition_weights = []\n    \n    for condition in ['spinal', 'foraminal', 'subarticular']:\n        condition_indices = solutions.loc[solutions['condition'] == condition].index.values\n        condition_loss = log_loss(\n            y_true=solutions.loc[condition_indices, target_levels].values,\n            y_pred=submission.loc[condition_indices, target_levels].values,\n            sample_weight=solutions.loc[condition_indices, 'sample_weight'].values\n        )\n        condition_losses.append(condition_loss)\n        condition_weights.append(1)\n        \n    any_severe_spinal_labels = pd.Series(solutions.loc[solutions['condition'] == 'spinal'].groupby('study_id')['severe'].max())\n    any_severe_spinal_weights = pd.Series(solutions.loc[solutions['condition'] == 'spinal'].groupby('study_id')['sample_weight'].max())\n    any_severe_spinal_predictions = pd.Series(submission.loc[submission['condition'] == 'spinal'].groupby('study_id')['severe'].max())\n    \n    any_severe_scalar = 1.0\n\n    any_severe_spinal_loss = log_loss(\n        y_true=any_severe_spinal_labels,\n        y_pred=any_severe_spinal_predictions,\n        sample_weight=any_severe_spinal_weights\n    )\n    condition_losses.append(any_severe_spinal_loss)\n    condition_weights.append(any_severe_scalar)\n\n    print(\"final score during training : \", np.average(condition_losses, weights=condition_weights))\n    \n    return np.average(condition_losses, weights=condition_weights)","metadata":{},"execution_count":null,"outputs":[]}]}